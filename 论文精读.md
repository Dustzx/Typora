## 论文精读

方法论：

三遍：

1. 标题+摘要+结论+实验部分图表 最终决定是否继续读
2. 重要图表的详细内容+圈出引用文献 
3. 复现作者的思路，并有自己的想法

<a name=''>-</a>[原文](papers/.pdf)

①标题+作者

②摘要

③结论

④导言

⑥模型

⑦实验

⑤相关工作

⑧评论

## 导航栏

非对话

- [Transformer](#p1)
- [Bert](#p2)
- [ResNet](#p3)
- [GPT](#p4)
- [GPT2](#p5)
- [GPT3](#p6)
- [Open-Prompt](#p7)
- 

对话相关

- [LCCC](#d1)
- [GODEL](#d2)
- [南洋理工大学对话系统综述](#d3)
- [GAN](#d4)
- [UniDS](#d5)
- [ConvLab-2](#d6)
- [UBAR](#d7)
- [InstructGPT](#d8)
- [医疗对话系统综述](#md1)
- [DIALMED](#md2)
- [Medical Dialogs for COVID-19](#md3)
- [Task-oriented Dialogue System for Automatic Diagnosis](#md4)
- [HRL](#md5)
- [DxFormer](#md7)
- [Diaformer](#md8)
- 

数据集

- [ReMeDi](#c1)
- [A benchmark for automatic medical consultation system](#c2)



## 非对话

### 1. Transformer 

<a name='p1'>-</a>[原文](papers/NIPS-2017-attention-is-all-you-need-Paper.pdf)

②主流的序列转录模型（由所给序列生成目标序列）大多都基于复杂的循环或卷积神经网络，都有一个编码器和解码器。其中表现最佳的模型也会在编码器和解码器之间使用到注意力机制。基于注意力机制作者提出了一个新的简单的神经网络架构，**Transformer**，该模型仅仅基于注意力机制。

③Transformer 是第一个仅仅使用注意力机制的转录模型，它将之前的在编码解码器之间使用的循环层替换为了multi-head self-attention

在机器翻译这一任务上，Transformer训练地比其他传统的架构都要快。

④RNN对于一个序列的计算是从左往右一步一步做，对于第t个词会计算隐藏状态ht，该ht由前一个词的ht-1和当前词一起决定。该时序性的计算使得并行难以进行。

​	并且Attention机制早已应用于编码器与解码器的结合部，用来使编码器的东西很有效地传给解码器。

​	Transformer不再使用之前的循环神经层，而是仅使用注意力机制去描绘输入和输出之间的全局依赖关系。它支持更强的并行，并且可以在更短时间内完成更为高质量的任务。

⑤  Extended Neural 、GPU ByteNet 、ConvS2S都通过使用卷积神经网络为基本单位进行构建，并行计算所有输入输出位置的隐藏表示，从而减少顺序计算增加并发度。对于这些模型，将来自两个任意输入或输出位置的信号关联起来所需的操作数量随着位置之间的距离而增长，对于ConvS2S来说是线性增长，对于ByteNet来说是对数增长。

​	而在Transformer这些运算的数量被减少到了常量级别，以此为代价的是由于注意力权重位置的平均化导致的辨识度的降低，对于这一缺点，采用Multi-Head Attention机制来解决。

​	Self-attention,或者称为intra-attention，是将一个序列中不同位置关联起来的注意力机制，以计算序列的表示。

​	Transformer是第一个只使用自注意力机制来做encode、decode架构的模型

⑥ 大多数有竞争力的神经网络序列转录模型都有一个encoder-decoder架构。encoder将输入序列的符号表示x(x1,……xn)转换成一个连续的向量表示z(z1,……zn)。对于z decoder将一次解码出一个y最终生成序列y(y1,……yn)，每次生成都是一次auto-regressive自回归，对于yt则需要y1~yt-1作为输入。

 	Transformer也使用了encoder-decoder架构，具体来说该encoder-decoder使用了堆叠起来的self-attention 、point-wise和全连接层

​	编码器结构如下<img src="NLP学习记录.assets/1665126121911.png" alt="1665126121911" style="zoom: 67%;" />

输入先进入嵌入层，将词转换为向量，随后连接的是N层的由Muti-Head Attention以及Feed Forward(前馈神经网络)构成的块，【Add&Norm】中连接到Add的为

**残差连接**

(将浅层输出与深层输出求和 we hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping . To the extreme,  if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers 残差块使得训练很深的网络更加容易)，Norm为LayerNormalization

<img src="NLP学习记录.assets/1665126138890.png" alt="1665126138890" style="zoom:50%;" />

残差连接可以解决**梯度消失**的问题(防止梯度<1相乘后无限接近于0)，残差连接后使得梯度保持在1左右

在使用残差连接之前，更深的神经网络并不能比浅层神经网络具有更好的效果(更深的网络，误差率(训练+测试)反而更高)。

实际上浅层网络构建好后，后加的网络充当一个identity mapping 的话，深层网络的精确度不应该降低，但实际来说SGD并无法实现这一点。

残差连接则是将从前一层传递过来的$H(X)$不直接去学习，而是学习$H(X)-x$, 并在输出时加上那个减去的$x$.

即

《Identity Mappings in Deep Residual Networks》中介绍了各种residual块的设计。

​	LayerNorm与batchNorm比较(蓝色为batchNorm)，layerNorm是对一个样本所有特征进行计算，BatchNorm是对一个mini-batch中的一个特征进行计算

当输入为2D<img src="NLP学习记录.assets/1665126147831.png" alt="1665126147831" style="zoom:50%;" />

二者通过对数据的转置可以达到统一的效果

而RNN、Transformer中输入为3D，如图

<img src="NLP学习记录.assets/1665126156370.png" alt="1665126156370" style="zoom:50%;" />

由于LayerNorm、BatchNorm两种切法不同以及每个序列长度的不固定性，导致了BatchNorm在每次小批量计算时的均值方差的抖动相对较大 ，同时也导致其全局的均值方差不准确（可能新的序列长度过长或过短）；而LayerNorm小批量计算的是每个样本自己的均值和方差，并且也没有必要存储全局均值方差（测试时），故相对稳定。

<img src="NLP学习记录.assets/1665125059900.png" alt="1665125059900" style="zoom:50%;" />

解码器结构如下

<img src="NLP学习记录.assets/1665126164383.png" alt="1665126164383" style="zoom: 67%;" />

解码器的自回归机制(t-1时刻的输出作为t时刻的输入)，以及attention机制中能看到完整的输入，故需要带掩码的注意力机制即Masked Attention，来保证在t时间的输入不会看到t时间之后的内容

​	**Attention机制**就是将query查询内容根据键值对key-value中与key的相似度映射为一个output，其中key-value保持不变，随着query权重分配的变化，将会有不同的output。在计算相似度时，不同的Attention版本有不同的算法。(涉及到的所有数据都是向量)

​	Transformer在计算注意力时使用的是sclaed dot-product attention。该方法中query和key的维度相等，通过计算两个向量的内积来衡量其相似度，内积越大则相似度越高(？)（long相等的前提下）,**Attention(Q,K,V)=softmax(Q K内积/向量长度) V**。除以向量长度是防止两个向量长度比较长时，出现较大值的概率将会增加，该相对差距变大的可能性增加后使得softmax后该值更加靠近于1，剩余的值则更加靠近于0，在该种情况下softmax回归计算时梯度将会很小，不利于尽快收敛。而Transformer中的向量长度都是比较大的故应除以√dk。 计算流程图如下

<img src="NLP学习记录.assets/1665126171051.png" alt="1665126171051" style="zoom:67%;" />

##### Muti-Head Attention

<img src="NLP学习记录.assets/1665126183494.png" alt="1665126183494" style="zoom:67%;" />

相较于单个的注意力函数直接去计算高维的向量，将其投影到低维度并行地去计算更有好处 ，如上图将V、K、Q分别进行投影，投影h次，而每次投影时的W是一直在学习的。
$$
MultiHead(Q,K,V) = Concat(head_1,……,head_h)W^o
$$

$$
head_i= Attention(QW_i^Q,KW_i^K,VW_i^V)
$$

##### Position-wise Feed-Forward Networks

实际上是一个全连接的前馈神经网络，用来作用于每一个词(position)
$$
FFN(x) = max(0, xW1 + b1)W2 + b2
$$
W1将d=512的x扩大到d=2048，线性相加后Relu，然后用W2将维度降回512，最后再线性相加

##### Positional Encoding

用与embedding后数据位数等长的数据来表示该数据原始的位置信息，相加后即携带了该词的位置信息 		

⑦编码器和解码器的embedding 由于使用了统一的字典所以共享权重

⑧**评价**：Attention并不是ALL you need，其中的前馈神经网络、残差连接都缺一不可 。

### 2. Bert

<a name='p2'>-</a>[原文](papers/Bert.pdf)

②Abstract

Bidirectional Encoder Representations from Transformers

Bert全称为transformer模型的双向编码器表示

bert使得NLP的语言模型预训练正式出圈，它与最近的语言表示模型不同，bert通过联合所有层中左右的上下文信息，使用无标签的数据来训练深层双向的表示。预训练的bert模型只需要一个额外的输出层就能得到一个不错的结果。

（论文成果在摘要中写明基于什么工作，并且相对于该工作有何提升，再给出具体的实验数据，绝对精度+与当前最优相比提升的精度）

It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MutiNLI accuracy to 86.7% (4.6% absolute improvement) and SQuAD v2.0 Test F1 to 83.1(5.1 point absolute improvment)

已经存在的预训练模型分为基于特征的、基于微调的。

ELMo则属于基于特征的，每个下游任务都要构造一个与其相关的神经网络(RNN架构)，将预训练好的表示作为一个额外的特征同输入一起放入模型，使得模型训练起来比较容易。

GPT则是基于微调的，预训练好的参数在下游只需要微调

以上两个方案在预训练时都使用相同的目标函数，并且都使用单向的语言模型（为预测模型，预测下一个时刻所要输出的语言，故为单向）。

Bert则可用''带掩码的语言模型''(Masked language model, MLM)来减轻语言模型单向的限制，其灵感来自**Cloze task (Taylor，1953)**，具体来说，每次随机从输入中选择一些tokens并将其掩盖，目标函数则去预测这些被盖住的词（相当于进行完形填空），MLM允许去看左右两边的信息，这就使得我们可以训练出双向的深的Transformer

Bert是第一个在句子层面和词元层面取得好成绩的微调模型

③conclusion

最近一些实验表明，大量的、非监督的预训练对于很多语言模型来说是非常好的，这使得一些即使训练样本比较少的任务可以享受深度神经网络。bert的主要成果就是将已有成果拓展到了深的双向的架构上来，使得同样的预训练模型可以处理大量的不一样的NLP任务

⑤相关工作

非监督的基于特征的工作(ELMO)

非监督的基于微调的工作(GPT)

有标号的数据上做迁移学习

⑥BERT

该框架有两个步骤：1）预训练 2）微调

预训练时模型是在没有标号的数据集上训练的。

在微调时bert模型的权重被初始化为预训练时得到的权重，所有权重在微调时都会参与训练，并且使用的是下游任务的有标号的数据。

每一个下游任务都会单独建立一个模型并进行微调。

bert使用的架构是多层双向的Transformer编码器，该架构基于Transformer原始代码。

输入输出的表示上，输入统一为一个序列，从而无差别地表示一个句子或多个句子。这使得一个句子可以是连续文本中的任意跨度，而不是一个真实语义上的句子。

bert使用WordPiece去切词，每个序列的第一个词永远是[CLS(classificiation)]。句子之间用[SEP]特殊标记来分割。并且可以通过学习到的嵌入层来区分token属于A句子还是B句子

 <img src="NLP学习记录.assets/1665126193703.png" alt="1665126193703" style="zoom: 67%;" />

input经过三层embedding后求和，分别是词元本身的向量，所在句子信息向量和整体的position向量(可学的)，如下图所示。

<img src="NLP学习记录.assets/1665126208275.png" alt="1665126208275" style="zoom:50%;" />

以上为预训练和微调的相同部分。

预训练任务1：

在预训练时对于每个序列的wordpiece的词元随机选取了15%来进行替换，但由于微调时不存在[MASK]符号，这将导致预训练和微调时数据的不匹配。为了缓和这一问题，将15%被选中的词元中80%的用[MASK]替代，10%的随机替换一个词元，剩余10%不进行操作。以上三种情况都会被标记为用来做预测。

预训练任务2：

预测一个句子对中两个句子是不是相邻

在训练样本中：

50%概率选择相邻句子对：<cls>this movie is great <sep> i like it <sep>

50%概率选择随机句子对：<cls>this movie is great <sep> hello world <sep>

将<cls>对应的输出放到一个全连接层来预测

微调时由于句子对放到了一个Transformer块中，所以self-attention可以来回看，比起encoder-decoder架构更优，由此付出的代价是无法再做机器翻译了。

微调

单文本分类(如情感分析和测试句子语法可接受性）

<img src="论文精读.assets/1667232047609.png" alt="1667232047609" style="zoom: 67%;" />

文本对分类或回归(如自然语言推断和语义文本相似性)

<img src="论文精读.assets/1667232191946.png" alt="1667232191946" style="zoom:67%;" />

文本标注（词元级别的任务如词性标注）

<img src="论文精读.assets/1667232244055.png" alt="1667232244055" style="zoom:67%;" />

问答

![1667232333468](论文精读.assets/1667232333468.png)

 在给定问题和段落的情况下预测段落中文本片段的开始和结束。 

### 3. ResNet

<a name='p3'>-</a>[原文](papers/ResNet.pdf)

②摘要

提出了一个可以简化深层神经网络训练复杂程度的残差学习块，并通过大量实验证明了，残差网络更容易去优化，并且在相当深的网络中仍然能提高精度。ResNet在ImageNet数据集上，使用比VGG Net深8倍的层数，即152层，仍然有更低的复杂度。这些层ResNets在ImageNet测试集上的错误率仅为3.57%。这一结果在ILSVRC 2015分类任务上排在首位。本文也完成了在CIFAR-10数据集上用100和1000层的结果分析。

③结论

CVPR要求正文不能超过8页，故由于本文实验结果太多，最终没有结论

本文优势：We can fairly compare plain/residual networks that simultaneously have the same number of parameters, depth, width, and computational cost(except for the negligible element-wise addition).

④导言

不收敛->精度不高->ResNet提升精度

显然不同数据集上结果较好的，都是使用较为深的神经网络。但好的神经网络却不是简单地去堆叠层数就有效果的。这就是由于梯度消失、梯度爆炸的存在，这一问题会阻碍模型数据的收敛，但也被初始化时的归一化操作和中间的归一化层较好地解决了。收敛问题解决后，仍然存在着深层神经网络精度不高的问题，这一相较于浅层神经网络而言精度下降的问题，并不是由于模型的过拟合导致的。

解决这一问题的方法是，将新添加的层采用identity mapping（恒等映射），其他层相较原来的浅层网络模型不变。

本文则是采用了另一个方法解决degradation问题，一个深的残差学习架构。将下层的映射定义为$H (X)$，对于叠加的非线性层采用的映射为$F(X)=H(X)-X$, 原本的映射就成了$F(X)+X$. 该映射可以被认为是一个带短接的前馈神经网络。Shortcut connections(短接)是指跳跃一层甚至多层的一个恒等映射，该短接会与残差块的最后一层输出相加，如图所示

<img src="论文精读.assets/1665407343887.png" alt="1665407343887" style="zoom: 67%;" />

这一短接操作，既没有增加额外的参数，也没有增加计算的复杂度。整个网络也仍能使用随机梯度下降算法通过反向传播来进行端到端训练。

在使用ImageNet为数据集进行的对比实验中发现，1）使用残差连接块的深层网络容易去优化，而对应的不使用残差连接块的网络训练错误率会随着网络的深度增加而变高。2）残差网络的精确率会随网络深度的增加而提高。这一实验效果也同样出现在CIFAR-10数据集上。具体来说，在ImageNet 测试集上的Top-5 error达到了3.57%，并且在ILSVRC 2015分类竞赛上赢得了第一名。不仅如此，这一深度学习模型还有很好的泛化性，在ImageNet detection、ImageNet localization、COCO detection、COCO segmentation都拿到了2015年竞赛的第一名，这说明了残差连接的普适性。

⑤相关工作

有做过Residual Representation的：

VLAD、Fisher Vector(a probabilistic version of VLAD)

与残差连接公式出现的: "highway networks"，该网络的短接操作是连接门控的，该门控可以对短接通过参数进行调整，而不像残差连接中的短接，是参数无关的。该方法的弊端是，当门控参数趋近于0时，短接的效果将会消失，这与不进行短接并没有区别。并且‘’highway networks‘’文章中并没有表明深度超过100层时精确度是否有提升(多少有点杠，highway文章中最深100 layers)

⑥模型

<img src="论文精读.assets/1665463403175.png" alt="1665463403175" style="zoom:50%;" />

该残差块等价于公式
$$
y = F(x, \{W_i\}) + x.
$$


 其中$F(x, {W_i})$表示的是需要学习的残差映射，对应上图为$F=W_2σ(W_1x)+b$，σ此处使用的是relu函数，shortcut connection短接操作即实现了$F(x)+x$,并且在进行短接之后，又进行了一次relu操作。

公式中F和x的维度必须是相等的，当由于进行维度变化导致维度不一致时，可以引进一个$W_s$，将公式改为：
$$
y=F(x,\{W_i\})+W_sx.
$$



<img src="论文精读.assets/1665492921126.png" alt="1665492921126" style="zoom:67%;" />

残差块的大小(即中间跨越的层数)是可以变化的，即可以跨越多个层，本文使用的是2~3层。但是连接只跨越一层时公式(4)的效果就等价为了$y=W_1x+x$，相当于残差退化为了一个bias，故对模型的精准度没有任何帮助。

另一个重要的点是，残差对于不同类型的中间层都有着优化效果，比如中间层是MLP、CNN都可以

公式(4)当且仅当输入输出维度相同时才可以使用，当维度不同时，本文给出了两种方法A：短接参数不变，对于增加的维度对应补0，该方法没有引入额外参数 B：使用公式(5)去进行维度匹配

在具体应用时，在每个卷积层后激活函数前，都进行了Batch Normalization操作，使用了批量大小为256的mini-batch通过随机梯度下降进行训练。并将学习率从0.1开始，每当错误率趋于平稳时进行除10操作。使用了weight decay 参数为0.0001并且将momentum设置为0.9，但并没有用dropout(因为没有全连接层

⑦实验	

图片分类实验部分，使用了ImageNet 2012 classification数据集，该数据集中包含1000种图片类别。训练集中包含128万张图片，验证集中有5万张。最终评估结果的测试集中为10万张，并且计算了top-1和top-5 error rates

为了对比，构建了两个18层和两个34层的模型，分别称为plain和ResNet，区别为ResNet添加了残差连接

![1665500059006](论文精读.assets/1665500059006.png)

实验结果显示：添加了残差连接的ResNet随着神经网络深度的增加，精确度仍能提升，而plain则会随着深度增加精准度下降。并且同为18层时，二者的效果区别不大。

![1665500334790](论文精读.assets/1665500334790.png)

但是，同为18层的ResNet的收敛速度相比plain要快(对比前期第一次骤降之前)。

实验还对比了对于三种不同的残差连接公式选择的影响，A：对于维度增多的采用补0升维度的策略 B：对于需要升维度的使用公式(5)即做投影，其他所有短接采用(4)即恒等映射 C：所有短接都用公式(5).

最终结果是C>B>A，但是他们之间的差别是细微的如下图

<img src="论文精读.assets/1665501290868.png" alt="1665501290868" style="zoom:67%;" />

由于使用C会增加模型的复杂度，故作者并未使用C，而是使用B来完成后续实验(B只会做几次维度改变，故复杂度增加不大)

⑧评论

question: 

1.$F(X)=H(X)-X$如何实现

2.BatchNormalization在relu之前和之后有什么区别

3.为什么34层residual复杂度比19层VGG低

4.为什么短接方案C相较B会更精确，即C中有什么因素导致精度变高

5.深度增加在不使用ResNet的情况下为什么越深越不好

Thinking:

1.残差连接进行短接时F(X)+X中X传递添加可学习的系数，并且该短接默认存在于任意两层之间。（即是否存在有一些时刻，进行短接后效果反而不好，而添加系数，并对关键节点系数波动范围加以限制，是否会比一直默认恒等映射要好）。论文highway中提到了使用gate门

2.有效果的原因是用短接来引导整个模型(同时也避免梯度消失)

### 4. GPT

<a name='p4'>-</a>[原文](papers/GPT.pdf)

①标题+作者

②摘要

自然语言理解任务多样性强，比如有文本蕴涵、Q&A、语义相似性评估、文本分类等。对于这些任务，虽然有大量无标记文本，但是对于具体任务的有标记数据却很少。于其分门别类地去设计适用于每个具体任务的模型，我们提出了一个可以从大量无标记数据集上训练出可以只经过具任务数据的输入和模型的微调就能适配各个具体任务的模型。我们这一无视具体任务的模型在常识推理上提升了8.9%的精准度，在Q&A上获得了5.7%的提升，文本蕴含上则有1.5%的提升。

③结论



④导言

在使用无标号文本时遇到的困难：1.难以选定优化目标函数以获得更容易迁移的文本表示2.如何有效地将已经学到的文本表示迁移到具体任务上

本篇论文使用了半监督方法应用于语言理解任务，该方法包括了无监督的预训练和监督的微调。其目的是使模型学习到一个通用的可以简单调整久就能迁移到其他任务的表达。

在这一设定中，并不要求目标任务与无标记的语料库在属于同一领域。

整个训练过程分为两个阶段：第一步是使用无标记数据建模语言模型从而学习到神经网络模型的初始化参数。第二步，使用目标任务的有标记数据集对模型参数进行微调。

整个模型的架构使用的是Transformer，其在机器翻译、文本生成、句法分析等多个任务领域已展现出了非常好的性能。该模型提供了有利于处理文本中长周期依赖/关联的更有结构性的记忆架构。在迁移阶段，处理的结构化文本输入将被看作是一个连续的词元序列，该调整使得微调时只需要稍微修改预训练模型就可以取得很好的效果。

论文中的方法在四种语言理解的任务上进行了评测：1.自然语言推理 2.Q&A 3.语义相似性 4.文本分类

⑤相关工作

本篇论文工作从属于**半监督学习**(pretrain无监督+fine-tuning有监督)

GPT、Bert所使用的方法已经被称为**自监督学习**(self supervised learning)

此前研究人员已证明了，通过使用大量无标记数据集去训练word embeddings可以将其用来提高多种任务的效果。但是这一方法，只是传递了词级别的信息，本文意在获取更高层级的语义信息。

先前也有人探索了使用短语级或句子级的嵌入同样也是使用大规模无标签的数据，最后在那个把文本编码成对于多种任务合适的向量表示。

**无监督预训练**其目的是找到一个表达良好的初始化，在早期有应用于图像分类、回归问题中。后来的研究证明，预训练作用类似于正则化方法，使得整个模型泛化性更强。最近的工作中，该方法被用来帮助在图片分类、语音识别、实体歧义消除、机器翻译等领域训练深度神经网络。

与GPT最接近的工作是使用语言建模目标去预训练神经网络，然后在具体任务上进行有监督的微调。但由于其使用的是LSTM模型，从而使得性能受限。

GPT则使用了transformer神经网络，从而能捕捉到更长范围的语义结构。其高效性，在自然语言推断、释义检测、故事续写任务上得以验证。

还有一些方法在具体任务上进行监督学习时，使用了从预训练或者机器翻译模型中得到的隐藏表示作为辅助特征，该方法增加了大量参数。

添加辅助的无监督训练目标是半监督学习的另一种形式，辅助NLP任务的方法，有如词性标注、组块分析、命名实体识别和语言建模，以提高语义角色标注，GPT同样也使用了辅助对象

⑥模型

**无监督预训练**

对于所给的序列tokens，GPT使用标准的语言模型建模目标去最大化以下公式的可能性
$$
L_1(U) =
\sum_{i}
log P(u_i|u_{i−k}, . . . , u_{i−1}; Θ)
$$
k是上下文窗口的大小，概率P是使用有θ参数的神经网络建模出来的，θ所代表的参数，由SGD训练而来。

实验中使用了多层的Transformer解码器作为语言模型，该模型对经过向量编码前馈神经网络的输入tokens进行了多头的自注意操作，最终生成了对于目标tokens的分布。
$$
\begin{aligned}
&h_0 = UW_e +W_p \\
&h_l = transformer\_block(h_{l−1})\space ∀i ∈ [1, n]\\
&P(u) = softmax(h_nW^{T}_e)
\end{aligned}
$$
U是tokens的内容向量，n是层数，We是token嵌入矩阵，Wp是位置嵌入矩阵

**有监督微调**

在训练好好公式(6)中的模型目标后，GPT调整参数去适应监督学习的目标任务。对于带标记的数据集C，其中的每个实例都由一个输入序列$x^1,……，x^m$和标签$y$构成，该输入序列经过预训练模型最终由transformer块的$h^m_l$进行激活，然后经过线性输出层通过参数$W_y$去预测y：
$$
P(y|x^1, . . . , x^m) = softmax(h^m_l W_y).
$$
这就是的我们可以去最大化以下目标
$$
L_2(C)=\sum _{(x,y)}log P(y|x^1, . . . , x^m).
$$
作者发现：加入语言模型作为微调的辅助目标有利于提高监督模型的泛化性，并且能加速模型的收敛。具体来说，将以下作为目标：
$$
L_3(C) = L_2(C) + λ ∗ L_1(C)
$$
总之，在微调阶段所需的额外参数就是$W_y$，并且为分隔符进行嵌入。

对于某些任务，仍然还需要对其输入进行结构化比如Q&A任务、文本蕴含任务将句子对有序化或者构造文档、问题、答案的三元组。GPT使用遍历风格的方法，将结构化输入转变成一个有序的序列，这样预训练模型就可以处理它了。这样的输入转变，使得我们在处理不同任务时避免了模型架构上大量的改变

⑦实验

在无监督预训练阶段使用的数据集是BooksCorpus，其中不乏有长篇幅的连续文本内容，使得生成式模型可以学到长距离的信息。其替代品是ELMO使用的1B Word Benchmark，但它的缺点是将句子级的数据随机打乱了，从而不利于模型的训练

模型整体同transformer区别不大，训练了12层的decoder，使用了带掩码的多头自注意(768维的状态和12个头)。对于全连接层使用了3072维的内含状态，优化策略使用了Adam，最大学习率是2.5e-4，学习率在前2000次更新时从0开始线性增长并开始使用cos函数降低到0。使用了batch_size=64的随机选取的mini-batch进行了100个epochs的训练，其中每个mini-batch中有512个连续的tokens

在微调阶段，除特殊情况外，直接沿用了预训练时的超参数设置，并为分类器添加了参数为0.1的dropout。对于大多数任务，use a learning rate of 6.25e-5 and a batchsize of 32。

⑧评论

question:

1. 为什么在无监督预训练相关工作中说：预训练充当了一个正则化方案，使得模型有了更好的泛化性(不应该是无监督预训练为文本在多维空间中预选到了一块较为好的区域？如果以类似字型接近度同等地在计算机表达中也靠近，那样无标记的数据在训练完后将天然地在多维空间中靠近)
2. 为什么模型介绍3.2中加入语言模型作为微调阶段的辅助目标有助于a)提升泛化性b)加快了收敛
3. GPT会从多任务训练中获益？

### 5. GPT2

<a name='p5'>-</a>[原文](papers/GPT2.pdf)

语言模型是多监督的多任务学习者

进行了多任务预训练使用超大数据集和深层模型，模型参数量达到了15亿个，并且在webtext的数据量下仍然欠拟合。

使用了zero-shot即在下游任务改造时不适用有标号的数据，使用该方法后在下游任务改造时不能出现模型从未见过的特殊符号，故需要新的方法对模型进行prompt提示

### 6. GPT3

<a name='p6'>-</a>[原文](papers/GPT3.pdf)

对比zero-shot、one-shot、few-shot



<img src="论文精读.assets/1665931747476.png" alt="1665931747476" style="zoom:67%;" />



few-shot无法做到将上次的同类问题的提示记住，而是每次预测都要添加提示信息

局限性：1）长文本生成上比较弱 2）有结构和算法上的局限性 ，不能像bert一样能够往前看 3）每次预测下一个词时名不能分辨出已知词哪个更为重要 4）样本的有效性不够 5）多样本进行上下文学习时不确信其是否从头开始学，还是从之前所学样本中找出相关

---

### 7. Open-Prompt

<a name='p7'>-</a>[原文](papers/Open-Prompt.pdf)

①标题+作者

一作丁宁清华大学计算机科学与技术系博士生。师从郑海涛教授，也得到了刘知远教授的共同指导。主要研究自然语言处理和机器学习。尤其是知识表示、提取和应用。

②摘要

提示学习已经称为NLP新范式，即直接调整预训练模型来完成完形填空风格的预测、自回归建模或者序列到序列的生成。然而对于提示学习的应用仍没有一个具体的框架。现存的提示学习代码库，通常是无规范的，只能局限地应用于某些具体的应用场景。导致该情况的是由于一些比如：无法统一的模板化策略、初始化策略和verbalizing strategy等, Open-prompt即提供了统一的方法，**其组合能力允许将不同的预训练模型自由组合**，具有很强的可扩展性 。

③结论

④导言

预训练语言模型引领了NLP的新时代，早期，调整预训练模型使其能完成各种具体的NLP任务时使用预训练+微调的范式，其需要额外的参数和具体任务的训练目标(损失函数)。但从T5和GPT-3开始，研究者发现文字提示或说明对于PLM有很好的引导作用。

以情感分类为例，需要设计一个模板和标签-单词映射器verbalizer，模板即文本+标识符号。假设template是"<text> it is <mask>"其中<text>代表原始的文本，此处映射器verbalizer是{“positive”:“great”, “negative”:“terrible”}

句子“Albert Einstein was one of the greatest intellects of his time.” 将会被预定义的模板包装为“Albert Einstein was one of the greatest intellects of his time. It is <mask>”，包装后的句子将经过分词后输入PLM去预测<mask>上可能出现单词的分布，从原始文本中可直，此处我们希望得到‘’great‘’的概率比“terrible”的概率大一些。

之后围绕着如何构建模板、映射器、优化和应用来对提示学习这一新范式展开了研究。

提示学习可以被认为是与训练语言模型、人类先验知识和具体NLP任务的综合。现有的深度学习或自然语言处理库并不能很好的支持提示学习的应用，并且也没有一个基础的规范。先前工作都是在最有效的传统微调的方法框架上做最小的修改，导致了很差的可读性甚至难以复现。尤其是提示学习的表现受模板和映射器选择的影响极大。目前也没有一个为提示学习设计的开源框架，使得新旧工作进行严格对比非常困难。

本文一大卖点就是设计的提示学习框架中支持多种任务格式(分类任务和生成任务)、PLM(MLM、LM和Seq2Seq)、提示模块(不同的模板和映射器)的灵活组合。比如我们可以非常便易地将前缀微调与文本分类任务相适配。OpenPrompt这一特性可以使得用户在不同任务上评测自己提示学习模型的泛化性，而不局限于具体某个任务。

OpenPrompt具体设计有：Template类、Verbalizer类、PromptModel类

Template中为实现多种模板的统一范式，设计了新的模板语言，该语言可以实现为对应特征进行词元token级别的定制化，比如用户可以定义哪些词元是共享词嵌入的、可训练的或这些词元应进行怎样的后期加工处理

⑤相关工作

传统的微调面临着两个问题：1）该方法会在预训练与微调之间产生一个鸿沟2）随着模型参数量的增加，微调的可操作性变得越来越小

⑥模型

**Combinability**

在Open-prompt的框架下，从模型观点来看，T5将不再仅用于预测寿命，GPT将不再只用于生成任务

从提示学习的角度来看，前缀调优将可以用来进行分类任务，软提示也将能用来完成生成任务。

**Pre-trained Language Models**

由于提示学习意在通过减少预训练与下游任务应用之间的区别去提高精度，因此介绍了不同的PLM

预训练语言模型分为三大类：MLM、自回归风格的LM、seq2seq模型(常见的有T5、MASS、BART)

OpenPrompt支持直接从huggingface transformers直接加载预训练模型

**Tokenization**

在设计好模板后，原本具体应用于具体的输入以及模型的分词方法，将会变得耗时且有错误率

其封装好的数据处理API可以同时处理输入和模板，组件对从输入和模板融合的复杂信息进行分词，根据预训练语言模型选择的不同，OpenPrompt自动选择合适的分词器

**Template**

模板模块将原始文本与文字的或是软编码(可训练的)模板打包在一起，OpenPrompt中所有模板都继承自一个基类其中含有共通的特性和抽象方法

先前对于模板的设计，有人工编写的和纯软(可训练的)的模板。后出现的二者的混合版本效果有时会更为好一点，最近的一些工作中的提升是通过修复大量的手工词元，同时调优一少部分其他词元来实现。

模板语言借鉴了python中dict字典的语法特点，这样设计可以同时保证灵活性和简洁性

具体设计为一个模板节点由一个text和一个特征描述组成。在模板语言中，每个词元的特征是可编辑的，如设置一些特征共享embedding，设计特征如何进行后处理。

![1666957558977](论文精读.assets/1666957558977.png)

**Verbalizer**

标签单词映射器在分类任务中是必不可少的

**PromptModel**

该类实例化的对象负责训练和推理，它包含PLM、模板对象，和一个标签单词映射器(可选)

基类中使用了一种模型无关的前向传播方法去预测应该加掩码的单词位置，从而可以无视预训练中的目标函数，只调用API就能”预测需要预测的位置的单词(即找到合适的加mask的位置)“

**Training**

从参数可训练角度出发，提示学习的训练可以分为两种策略：1）同时调整提示和预训练模型 2）只调整提示的参数，而预训练模型保持不变

其中第2个方法被认为更有前景

⑦实验

⑧评论



## 对话生成

### 1.大规模中文短对话数据集LCCC

### (Large-scale cleaned Chinese conversation dataset)

<a name='d1'>-</a>[原文](papers/LCCC.pdf)

①标题+作者

清华大学王义达  https://www.bilibili.com/read/cv8946802 、郑银河

②摘要

开放域短文本对话需要一个大规模高质量的数据集来训练，本文即提出了一个清洗过的中文开放域对话数据集LCCC，其含有一个base版本内有680万个对话，另外一个large版本，内有1200万个对话。数据清洗使用了严格的标准，该标准由一系列规则和一个在人工标注的11万个对话数据对上训练出的分类器组成。同时，作者也分别使用两个数据集在GPT2进行了预训练发布了两个预训练模型LCCC-base、LCCC-large。

③结论

④导言

BERT推动了自然语言理解类任务，GPT极大提升了自然语言生成类任务的精确度。

除了这些高效的基于Transformer的大模型，一个好的对话数据集同样很关键。尤其在开放域对话系统中，现存工作大都是从Twitter、Reddit、OpenSubtitles和其他公众资源爬取了英文语料库，并配合预训练模型，取得了很好的效果。

当前数据驱动的对话系统大都是基于公共平台资源或者众包数据集。公平平台资源规模大，但有大量噪声数据需要被清理；众包资源质量高但是数据量小。



LCCC中的数据由Weibo数据和其他中文语料库组成

但是中文预料库的缺少使得我们去预训练中文对话模型非常困难



本文所创建的LCCC可以作为开放领域中文对话生成的benchmark数据集

本文提供了两个预训练模型，其先在中文小说数据集上进行预训练，再使用LCCC进行后训练(post-trained)

⑤相关工作

前面说了公开的社交媒体资源来源，其来源广泛但所爬取的资源确实带有很多噪声的即脏数据。再就是基于众包的一些高质量数据集，这些数据集是为高级的对话任务而构建的，比如为基于知识的对话生成提供的数据集[wizard of wikipedia(WOW)](papers/wizard of wikipedia (WoW).pdf).、[document grounded conversations(DOG)]().为角色增强的对话生成构建的[PERSONA-CHAT](file:\\\). 以及为情感对话生成构建的[DailyDialog](file:\\\)

这些基于众包的数据集虽然质量高但是数量太少。

GPT出现后在很多文本生成任务上都达到了SOTA水平，预训练模型也就在对话生成领域火了起来。[DialoGPT](papers/(DialoGPT)Large-Scale Generative Pre-training for Conversational Response Generation.pdf) (其声称已经被[GODEL](papers/GODEL Large-Scale Pre-Training for Goal-Directed Dialog.pdf).超越）)即提供了一个在英文开放域对话的预训练模型，该预训练模型使用GPT-2在147millions个在Reddit上的对话进行了后训练

[Meena](论文精读.papers/Meena.pdf)使用有着26亿个参数的Evolved Transformer在大量英文社交媒体对话数据集上进行了预训练，该数据集中包含了400亿个单词。

Chinese GPT模型所使用的数据集是Chinese Wikipedia2 (17亿个 words)和Chinese News (92亿个 words)

本数据集使用的是从微博上爬取的7千9百万个对话，对些对话进行严格地清洗后得出了**LCCC-base**。 又在添加若干中文对话数据集后在相较base版较为宽松的清洗后得到了**LCCC-large**。整个清洗的过程包括基于规则和基于分类分类器的过滤

**数据收集**

LCCC-base收集数据分两阶段，首先是选取种子用户，其中有一些是手工选取自有关注专业的大众新闻媒体的账号。之后我们认为在这些新闻下发表评论的用户都是高质量用户，因为机器账号通常对这些日常新闻并不感兴趣

第二阶段，收集这些被选中用户的对话。这些用户所发的微博包括其下面的评论都被收集起来构造成树结构。其中任意一个根到叶子的路径都是一个对话，对其使用深度优先搜索进行重构后就得到了7千9百万个对话原始文本。

LCCC-large 先是从Chinese Chatterbot Corpus、PTT Gossing Corpus、Subtitle Corpus、Xiaohuangji Corpus、Qingyun Corpus and Tieba Corpus收集了单轮对话数据。收集了 Douban Conversation Corpus , E-commerical Conversation Corpus and a Chinese chat corpus 作为多轮对话数据，在混合上先前79million个对话后使用相较LCCC-base较为宽松的清洗规则后得到LCCC-large

**清洗过程**

基于规则的：

1）删除一些特殊符号 2）将30轮以上的对话分割为多个少于30轮的对话3）删除回复太长或太短的对话4）对于重复6遍以上短语或词只维持一个副本5）删除识别为广告的对话6）删除带有万能回复的对话

同时也将一些噪声添加进了黑名单1) dirty words,sensitive words, and dialect; (2) special topics words such as levofloxacin; (3) name, appellation and unknown abbreviation; (4) special symbols and emoji; (5) platform signs such as ads, pictures, and videos related words

基于过滤器的：

很多语义语法类层面的和一些依赖于上下文的对话很难被基于规则的方法过滤掉。因此本文使用了两个BERT分类器进行了进一步过滤，综合评价精准度、召回率和F分数等可信度高的分数选择了一个最可信的过滤阈值

第一个BERT分类器在手工标记的10万个对话上进行训练。对话被标注为有噪声的规则：(1) The response is not fluent or there are serious typos in the sentence, (2) The information of the response is incomplete; (3) The topic of dialogue is time-sensitive, (4) Festivals, places, gender and time which are not mentioned in the post appear in the response (5) The post and the response are irrelevant.下图为例子

<img src="论文精读.assets/1667455225016.png" alt="1667455225016" style="zoom:67%;" />

该分类器的精度在测试数据集上达到了**73.76%**

社交媒体中的一些对话往往涉及超出文本外的语境，这些看似无主题的对话也是应该被过滤掉的，第二个BERT分类器即做这个工作，其分类精度在测试数据集上达到了**77.60%**。

**统计数据和结果**

Avg.words代表每句话里单词的平均数量，文本的分词工作是使用Jieba进行的。本文用自己的黑名单评估了STC(single-turn short text conversation)数据集的噪声级别，结果显示其中60%的对话有dirty words, sensitive words, special symbols, etc. 使用STC训练出的模型相较于在LCCC上训练的生成的黑名单词汇有五倍多。以下为LCCC数据集相关统计信息

![1667457638779](论文精读.assets/1667457638779.png)

LCCC数据集与现存其他数据集对比图：

![1667457672465](论文精读.assets/1667457672465.png)

⑥模型

**模型架构**

![1667467662720](论文精读.assets/1667467662720.png)	

>[GPT2](papers/GPT2.pdf)对于[GPT](papers/GPT.pdf)的修改
>
>Layer normalization (Ba et al., 2016) was moved to the input of each sub-block, similar to a pre-activation residual network (He et al., 2016) and an additional layer normalization was added after the final self-attention block. A modified initialization which accounts for the accumulation on the residual path with model depth is used. We scale the weights of residual layers at initialization by a factor of 1/
>√ N where N is the number of
>residual layers. The vocabulary is expanded to 50,257. We also increase the context size from 512 to 1024 tokens and a larger batchsize of 512 is used.

模型部分使用的是基于transformer的GPT，decoder使用的是带掩码的多头自注意力块

对于给定的回复和历史对话信息，y = (y1, ..., yL)和U = {u0, ..., un}对于生成的U($u^1_{n+1}, ..., u^{j−1}_{n+1}$) 通过利用最大近似估计maximum likelihood estimation $∏^L_{j=1} P(y_j|y_1, ..., y_{j−1}, U)$去生成$u^j_{n+1}$，直到遇到结束符截止

同[TransferTransfo](papers/TransferTransfo A Transfer Learning Approach for Neural Network Based Conversational Agents.pdf)一样将当前所说的语句与历史对话信息一同concate到了一个长文本序列。

>a sequence of input tokens for the model is constructed for each utterance by concatenating all the persona sentences of the current speaker (usually 4 to 6 sentences in the PERSONA-CHAT dataset) with a history of the dialog’s previous utterances (typically 3 to 5 previous utterances).

模型输入是word embedding, speaker embedding, 和position embedding的总和，word embedding、position embedding是在预训练阶段所学到的，speaker embedding则是在后训练或者微调时学到，speaker embedding用来表示不同的讲话人。同Bert一样将[CLS]作为序列的开始标记，[SEP]作为序列的终止标记

![1667465797551](论文精读.assets/1667465797551.png)

>(i) a personality sentence, (ii) an utterance from PERSON1 or (iii) an utterance from PERSON2. These additional embeddings are learned on the PERSONA-CHAT dataset during the fine-tuning phase.

同[DialoGPT](papers/(DialoGPT)Large-Scale Generative Pre-training for Conversational Response Generation.pdf)一样，整个模型是在一个中文预训练模型GPT_novel上使用我们的数据集进行的post-trained

在处理多轮对话时同DialoGPT一样 我们将对话中，从第二句到最后一句每句话作为历史句的回应(?不太懂)

具体模型以及训练次数![1666516405298](论文精读.assets/1666516405298.png)

**post-train的参数设置**

对于所有模型都选用AdamW(Adam对学习率不敏感的非常平滑的SGD，因此不必太多地去调参，效果与SGD+momentum差不多)为优化器，Noam作为学习率衰减方法，层数都为12层，注意力头数12，word embedding维度为768，position embedding 维度 513，最大学习率6.25e-5，batch_size=8，梯度累加=64

⑦实验

**微调设置和具体实现细节**

为了评价这些模型，将他们在STC数据集(contains 4.4M conversation pairs)上进行微调,将其随机划分为了训练、验证、测试集，测试验证集各有不交叉的2000个对话

>STC
>
> 这是一个基于Sina微博的数据集，是从一些中国搞NLP的高级知识分子的微博posts中爬下来的（posts的质量较高），但是comments（replies）是所有人都可以发的。 

本文使用的baseline：[GPT2chitchat](https://github.com/yangjianxin1/GPT2-chitchat)(本文写作时唯一一个中文对话预训练模型2019.12.9,基于GPT2与训练了50w个中文对话)、Vanilla transformer、Attn-Seq2Seq

GPT_novel微调了30个epoch，其他模型(CDialGPTLCCC−base、CDialGPT2LCCC−base、CDialGPTLCCC−large)微调了10个epoch。微调时使用相同的batch_size和相同的梯度累加数，其他的超参数也更后训练阶段设置相同。

transformer and Attn-Seq2Seq不经过预训练在STC数据集上训练直到其收敛(consists of 6 layers of GRU with Bahdanau attention mechanism the dimension of hidden states is set to 768,The layers of the transformer are also set to 6，以使其与本文的预训练模型具有差不多的参数量)

Bahdanau attention 架构如下：

![1666880206930](论文精读.assets/1666880206930.png)

对于所有模型学习率都使用AdamW优化器从6.25e-5 线性衰减到0

CDialGPTLCCC−large在STC上微调后的生成样例：

![1667484083999](论文精读.assets/1667484083999.png)

人机交互对话样例和自交互对话样例：

![1667484217031](论文精读.assets/1667484217031.png)

 所有的回复均使用 [Nucleus Sampling](papers/Nucleus Sampling.pdf) 的方法采样得到 (p=0.9, temperature=0.7)。 

**模型评估**

自动评测：使用BLEU和distinct n-grams，

由于BLEU不能很好地反映生成结果的质量，本文又采用了Greedy Matching来评估帖子和生成的回复之间在单词级别的相关性，以及使用Embedding Average来评估其在句子级别的相关性。除了词汇量与其他模型不同的GPT2-chichat外本文还给出了模型的困惑度，评估数据如下：

![1667491085727](论文精读.assets/1667491085727.png)

人工评测：

对于三个评分员每个模型提供200个生成样例，从流畅性、相关性和信息量三个角度来打出2/1/0分，打分结果如下：

![1667491263272](论文精读.assets/1667491263272.png)

本文还使用了Fleiss kappa来评估评分者间的意见一致性，打分结果为0.39-0.44之间表明了较好的一致性。

⑧评论

___

### 2.GODEL : Lare-Scale Pre-Training for Goal-Directed Dialog<a name='d2'>-</a>

<a name='d1'>-</a>[原文](papers/GODEL.pdf)

①标题+作者

- 微软雷德蒙德研究院
-  哥伦比亚大学 

，一作[pengbaolin](https://www.microsoft.com/en-us/research/people/bapeng/)

②摘要

GODEL使用了新的基于知识的预训练方法来使模型更好地支持那些，需要对当前对话引入外部知识的下游任务来使其产生更好的回复。实验对比了一系列基准模型，包含任务导向的对话、问答对话、需要基础知识的开放域对话，结果表明GODEL在人工评测、自动化评测上都达到了当前预训练对话模型(微调阶段使用few-shot)最好的水平(SOTA). 在本文评估方法中，新增加了一个特征，即**utility**有用性这个概念(即评估回复的有用性[extrinsic evaluation]，而不是只关注于其交流过程中相关的特征[intinsic evaluation]，即流畅性)。引入有用性特征后，更有助于提高评分者间意见的一致性以及自动化评分与人工评分的相关性。

③结论

④导言

GODEL是为general-domain一般域对话设计的完全开源的预训练模型。其有两大亮点：1.将预训练分为了三个阶段，

 1) Linguistic pre-training on public web documents to gain the capability of **text generation**. 

2) Dialog pre-training on public dialog data to learn to **chat like a human**.

 3) Grounded dialog(有基础的对话) pre-training to enable a dialog model to generate responses grounding on specific goals. i.从web文本中连续折叠数据ii.使用如Reddit之类的公开对话数据iii.一系列现存的支持基础对话任务的语料库

其中带有外部知识的对话语料库包括MS MARCO、DSTC7，其能使得微调时有效帮助到那些需要产生有关外部知识的回复。

2.GODEL的验证是有用性驱动的，使用的是一套为**开放领域任务导向的通用对话模型**(open-ended goal-directed general-domain dialog models)的少样本微调设计的基于有用性的基准。使用了该有效性检验方法后，GODEL对于任务导向对话的微调效果比其他大型的预训练语言模型要好。

没有一个鲁棒性的自动评估标准一直是多用途开放对话模型的一大问题，最近的一些SOTA预训练模型，往往因为缺少一个认同度高的评价标准而没有进行有意义的比较。

而要制定一好的标准，我们则要回归初衷，不应是只关注对话回复的流畅度和其社交能力这一从交流来看的内在维度，而应该关注其有用性这一外在维度，即对话系统所生成的回复应对用户有用才行。本文认为该功能有用性的外在维度是**general-domain**模型更适合的自动化评价方法

本文用GODEL在四个任务上进行fine-tuning，并探索有用性这一概念，这些任务有：任务导向的MultiWOZ、开放域目标导向的任务比如CoQA、Wizard of Wikipedia和Wizard of the Internet

GODEL相比于baseline DialoGPT在目标导向的任务上做的更好，对于在不同任务上的结果证实了本文方法的有效性。并且当聚焦于目标导向和外在评价时，评分者间意见更具有一致性且评估指标更具有相关性。

本文提供了多个版本作为未来工作的baseline，$GODEL_B$、$GODEL_L$、$GODEL^{GPT-J}_{XL}$

⑤相关工作

大规模的预训练模型对对话领域已经产生了巨大影响，比如DSTC、ConvAI就已经在竞赛中取得了好成绩，并且在任务导向、闲聊方向都得到了广泛应用。然而对于这些预训练模型的实验评估仍局限在内在的如Relevance、Informativeness、Humanness(human-like)还有各种基于字符重叠的自动化评估标准，DialoGPT提供的基于Reddit的预训练模型也即如此评估的。[Meena](papers/Meena.pdf)的评估着眼于Sensibleness合理性和Specificity明确性，同时也提供了一个新的自动评估方法SSA，从这两个维度去进行评估。[BlenderBot](papers/BlenderBot 3.pdf)的模型利用了各种技术包括人性化(human-like)、共情化、知识化，但其评估核心却是人性化(human-like)和新颖度。Plato-XL使用内在标准：Coherence, Inconsistency, Informativeness, Hallucination, and Engagingness。而Plato-XP在评估DSTC9-Track1、MultiWOZ 2.2、DuConv时使用了一些外在标准，但是都是使用的基于具体任务的自动评估(**ROUGE-L** for DSTC9, **Goal-Accuracy** for MultiWOZ, and KnowledgeF1 for DuConv)。

本文则是提供了更为统一化的对有用性的评测标准，即用统一的方式比如相同的注释结构

LaMDA在进行初步评估时使用了内在特征，但在人工评测阶段考虑了外在特征即有用性，这是同本文工作最接近的一个。

本文则是想通过对比外在内在特征，分析他们与具体任务和数据集的自动化评分的相关度。

作者又具体解释了

**Open-Domain Goal-Directed Dialog**

本文在目标导向这一基础上，想去生成更为自然且更具有用性的回复。

先前的一些任务导向的对话中已经用了大量的有用性的评测标准比如**Inform-rate** and **Successrate** for MultiWOZ，**Knowledge-F1** for Wizard of Wikipedia，这些**定制化**的评价标准往往具有异质性，并且只能应用于有限的子任务，这使得分析跨对话任务和数据集的结果较为困难. 本文解决这一局限性的方法为，提出了一个人工评测的统一标准，比如当一个评分员被要求为一个餐馆领域的对话系统进行评分时，他对于能给出推荐或者给出一些餐馆信息的系统所给的分数就应该比一个只会闲聊的系统要有更高的有用性分数。

有用性在任务导向对话中的普适程度就相当于在闲聊对话中的人性化(human-like)和有趣性，但其统一化的评分标准却很少被用在目标导向的对话系统中。

作者进一步对比了人工评分下的外在、内在评价标准，并且将其与自动化评分标准联系起来。

首先展示了使用Krippendorff’s alpha方法计算的评分者间意见一致性，该方法适用于Likert量表的众包评价，其特点为

(1)评价者的个数任意

(2)不同评价结果的数量任意

(3)可以为不同种类的评价结果设定不同的差异衡量标准

(4)允许数据不完整

(5)对于大数量数据和小数量数据的处理方法相同

![1668244462177](论文精读.assets/1668244462177.png)

如上说明有用性这一外部评测标准更具评价者间意见一致性。其中WoW数据集的内在特征评分者间意见一致性更高，其原因是该数据集中的对话更多地依靠了闲聊，并且在改定的语境中并不总是具有一个有用的概念占主导。CoQA数据集有用性的意见一致性低是由于其给出的总是短的基于事实的回复，这使得评分者不易去区分系统的回复。

之后作者又使用**斯皮尔曼等级相关系数**(关注两组数据的单调性，换句话说是两组数据的趋势 )分析了以上人工评价和一些自动化评价方法标准的相关程度。自动化评价方法使用了BLEU、BLEURT、BERTScore和chrF，

>The chrF metric is a lexical-match metric similar to BLEU, but is character-based rather than word-based and but has been found to be more robust than other surface-level metrics 

结果如下

![1668248085286](论文精读.assets/1668248085286.png)

由于区分开放式回复生成的内在和外在评分的质量这一做法还是比较新的，所以本文试图找到一些更适于评价这些不同特征的评价方法。

从上表可以观察到，这些评价标准往往与外在特征的评价更加相关。这一结果也是由于外在特征具有更好的评分者间意见一致性导致的。

并且可以发现基于语言模型的评价标准(BERTScore and BLEURT)在相关性上不如词汇匹配的评价标准，这是由于其关注于语言建模于是自然地将焦点放在了评测人性化(即更像人，e.g., fluency and well-formedness)，这就使得其对于有用性的辨识能力下降。作者对于chrF对于外在特征更有相关性的原因上并不是很清楚，但其推测在比如QA和基于知识的需要精准地获取事实信息比如年份或具体人名而不需要对其加以阐述。

作者有趣地发现安全性与自动化评分标准有着不错的相关性。任务导向对话中(MultiWOZ)，安全性与chrF有最好的相关性，在偏闲聊的对话中(WoW)则BERTScore与人工评测相关性更好。作者认为这一不错的相关性是由于对话中所引用的内容通常很安全。

这些评论者间意见性和相关性结果表明对于**开放式对话系统**采取外部评测更好。不论对话系统是否与具体的任务联系在一起，对话总是有一个或多个目标的，评判这些逐步实现目标的回复的有用性是自然且可取的。这些结果也同样说明了向外在特征转变可以使得对话自动评估不那么具有挑战性(即拉近了自动化与人工之间的距离)。对于Humanness(human-like)这一内在标准的评估主要还是保证对话系统不牺牲人性化(human-like)和安全性从而变得更为有用。

考虑生成一个具有高有用性的回复，作者将open-domain goal-directed 对话生成任务定义为：对于给予的源对话上下文$S=（s_1,……,s_N)$,以及环境$E$，目标是生成目标句子$T=(t_1,……，t_N)$.$P(T|S,E)$的条件概率可以被表述为一系列条件概率的产物：<span name='godel-eq1'>eq1</span>
$$
P(T|S,E)=∏_{n=1}^Np(t_n|t_1,……,t_{n-1},S,E)
\tag{1}
$$
$E$代表world的状态和外部知识(e.g., a database or results of a search engine)也即超越闲聊具有有用性所需的。在预训练阶段，$E$通常是不存在的，因为E往往是对于特定任务来说的，但是作者发现在预训练的第三阶段使用基础知识文本替代E有很好的效果，i.e., grounded dialog pre-training.

⑥模型

![1666616731830](论文精读.assets/1666616731830.png)

GODEL是在web文本上训练的标准的预训练语言模型。其使用了seq2seq的Transformer模型，如上图，根据给定的历史对话和环境去给出回复。下图是一个训练样本例子：

![1668080782761](论文精读.assets/1668080782761.png)

在预训练的第二个阶段即广域对话预训练，使用的数据集是从DialoGPT的Reddit评论链中摘取的。(which consists of 147M dialog sessions for a total of 6B tokens.)

预训练最后的有知识基础的对话，使用的是现有的支持基于知识生成回复的、传统的对话Q&A的和任务导向的对话数据集。

DSTC7 Task 2、MS MARCO、UnifiedQA、The Schema-Guided Dialog

本文构建了三个不同大小的模型1）220M个参数的基础版本$GODEL_B$，2）770M参数的版本$GODEL_L$，有175B个参数的$GODEL_{XL}$

基础版$GODEL_B$有12层encoder和12层decoder，其词嵌入的维度有768维。$GODEL_L$的encoder、decoder的层数翻倍，并且词嵌入有1024个维度。这两个模型是分别从T5和T5-Large初始化来的，并且基于HuggingFace仓库的版本。本文使用了HuggingFace中实现的BPE字节级别分词。

$GODEL_{XL}$是从GPT-3初始化来的，尽管由于版权原因无法发布，作者还是想在最好的模型上测试自己基于知识的微调方案。为了代表$GODEL_{XL}$，作者发布了基于GPT-J的一个预训练版本。

![1668087889478](论文精读.assets/1668087889478.png)

如上图，该替代版本的功能与GPT-3版本是相当的。

⑦实验

本文评估了两种配置的微调模型，few-shot和full。关注焦点在few-shot上，这是由于任务导向的对话数据集(e.g., MultiWOZ)构建的成本很高，并且比闲聊数据集更小，因此本文想评估微调样例相对少的情况下模型是否仍能表现地很好。并且这篇工作本身就是专注于对话领域的预训练，few-shot少样本学习能更好评估该预训练模型的效能。再者，少样本微调是现实应用场景中更为实际的方法

GODEL对于开放域目标导向对话任务只需要很少的带标签的数据样例去微调。本文通过在三种目标导向的对话(i.e, 知识基础的回复生成、任务导向对话、对话问答)数据集上进行微调来评测GODEL。

具体的数据集有Wizard of Wikipedia、Wizard of Internet、MultiWOZ、CoQA

对于few-shot微调，将从这些数据集中为每个任务的微调随机采样50个对话，并且使用它们原本的测试集用来评估。GODEL在每个任务上的微调使用的是相同的预训练配置，使用[公式1](#godel-eq1)

作为训练目标。最后基于在验证集上的困惑度分数选择最佳模型。

**Baseline pretrained models**

本文与T5、BART、DialoGPT和BlenderBot这几个预训练模型进行了比较。具体微调使用的是For T5, we fine-tune from both T5-base (T5B) and T5-large (T5L). For BART, we fine-tune from both BART (BARTB) and BART-large (BARTL). For BlenderBot, we fine-tune from BLENDERBOT400M, which is distilled from a 3B model.

**Automatic evaluation metrics**

基于评测有用性的角度，使用了一下评测函数

$F_1^R$评测预测与基于知识回复间的平均重叠

$F_1^K$评测模型回复与数据集中知识的重叠

$Inform$评测模型是否提供了能够满足用户的充足的信息

$Success$评测模型提供的信息是否包括所需的所有特征。

$The \space Combined \space score=（Inform+Success）*0.5+BLEU$

用来评价总体质量

除了以上有用性函数之外，本文还使用了BLEU、BLEURT、BERTScore和chrF

BLEU的分数基于corpus-level BLEU-4

 在表1至表5中，使用对最佳竞争对手的配对双侧t检验计算显著性。 

**Human evaluation setup**

使用轮次级别的人工评测去检验GODEL生成的回复是否1) useful, 2) human-like and 3) safe

使用Amazon Mechanical Turk众包平台雇佣了高素质评测员。首先向评测员展示对话历史、相关知识和由不同的系统(随机选择)生成的两个回复。之后让评测员考虑以下三个问题：

- 哪个回复更有用Extrinsic(i.e., contributes to making the conversation productive, especially towards achieving any stated goals)
- 哪个回复更像人说的Intrinsic(e.g., coherent, fluent, and natural)
- 哪个回复更具安全性Safety(e.g., friendly, polite, and empathetic, as opposed to harmful, biased, misinformative, or incomprehensible)

以上在一个满分为5分的Likert scale上进行评分。

**Automatic Evaluation Results**

所有任务在少样本微调下的结果：

![1668344896062](论文精读.assets/1668344896062.png)

全部样本参与微调：

![1668344935066](论文精读.assets/1668344935066.png)

需要注意到少样本微调下GODEL比T5好很多，但是全样本下则相差不多，这是由于GODEL使用与T5一样的模型进行训练，若两个模型都微调至收敛则会相差不大。DialoGPT、Blenderbot这些在闲聊语料库上训练出的模型表现得差是在意料之中的。

GODEL在基于知识生成的任务上(WoW、WoI)的**内在评估**分数有所提升(结果整合到了一个表，如下：)

![1668348177313](论文精读.assets/1668348177313.png)

MultiWOZ and CoQA在外在评测上有所提升

![1668348165986](论文精读.assets/1668348165986.png)

![1668348195646](论文精读.assets/1668348195646.png)

本文结果显示在少样本微调情况下，GODEL的BLEU分更高并且在$F_1^k$分数上与baseline模型保持了相同水平。

表4中GODEL的**有用性评分(Success)**比T5高了23.6，并且BLEU高了8.5. 表5中作为有用性评分函数的$F_1^R$关注回复的正确性。总之结果表示GODEL在少样本学习的微调设置下的有用性分数比baseline要好。但是BLEU分数并没有得到提升，这是由于CoQA的回复通常很短

 本文构建目标导向对话模型的方法适用于不同的PLM，例如T5和GPT-3 

![1668349743290](论文精读.assets/1668349743290.png)

上表中可以观察到$GODEL_{XL}$比$GPT-3$性能好了很多。这说明带有基础知识的预训练对于GPT-3在任务导向的对话上的应用是非常有用的。

GODEL预训练阶段的消融实验：

![1668354158334](论文精读.assets/1668354158334.png)

表中数据说明，只去进行对话预训练会使得模型变差。这可能是因为模型仅仅是学习了进行对话，而下游任务都需要基于知识去生成的能力。

**Human Evaluation Results**

由于GODEL和T5在自动评分时表现最好，因此本文拿它们两个进行比较。并且GODEL是从T5初始化来的，比较两者能直接评测基于知识预训练方法所带来的影响。本文的人工评分是从所有任务中随机选取共4137个样例来进行评估的

![1668354562820](论文精读.assets/1668354562820.png)

上表中展示的是总的胜率，GODEL在三种指标上都胜过了T5

 值得注意的是，GODEL在CoQA上的有用性得分与T5相似，但在对这项任务的人工评估中具外在和内在特征得分却更高，这可能是因为CoQA的目标比其他任务更明确 

⑧评论

thinking: 各领域现在的评价标准一定是最合适的吗，有哪些领域的亟待修改？修改评价标准后对领域内模型的发展趋势，以及模型进步的速度是否有影响？评测标准注重于有用性就是好的吗？

本文没给出第一阶段预训练的数据量？

分阶段递进预训练是必要的？

A survey：different works' evaluation methods and their correlation with attributes?

question：Third, few-shot fine-tuning is a realistic approach in application scenarios where it can facilitate fast turnaround of updated models and greater developer control over model characteristics.？？

**文末附录中有人工评测具体表**



---



### 3.Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey

[原文](papers/Recent Advances in Deep Learning Based Dialogue Systems A Systematic Survey.pdf)<a name='d3'>-</a>

①标题+作者

南洋理工大学

②摘要

现今对话系统都SOTA都是基于深度学习方法的，本文从两个角度出发：1）模型类型2）系统类型 来探讨目前SOTA水平的对话系统。从模型类型角度，探讨了principles, characteristics和广泛应用的具体模型。

从系统角度出发，探讨了1)任务导向型 2)开放域 对话系统也即两个主流的研究方向。

本文也回顾了对话系统的评估方法和数据集

同时也指出了可能的发展方向

③结论

④导言

如今基于深度学习聊天机器人已经不再死板化。其市场规模已经从2021年的26亿，增长到了94亿，且有80%的公司希望在2021年年底之前配置上自动聊天机器人。

根据对对话系统的不同应用将其分为了两大类：1）任务导向的对话系统(task-oriented dialogue,**TOD**) 2）开放域对话系统(open-domain dialogue,**OOD**)。

TOD解决了一些具体领域的具体问题，如预定电影票，预定餐馆等。

ODD则注重与用户不限于具体领域的，不以任务为导向的聊天，通常是以数据为驱动的。

TOD、ODD都可以被看作是一个从用户发送的信息$U = {u^{(1)}, u^{(2)}, ..., u^{(i)}}$到智能体回复$R = {r^{(1)}, r^{(2)}, ..., r^{(j)}}$的一种映射:$R =ϕ(U)$

在一些TOD、ODD中该映射又添加了外部知识/数据而变为$R =ϕ(U，K)$,下图即为例子

![1667292677237](论文精读.assets/1667292677237.png)

有些数据集为每一个对话对提供外部知识标注，比如在TOD中的外部知识即可以从数据库中获取；ODD中的外部知识则可以从常识知识图中检索到

传统的TOD由分为四个功能模块的流水线结构构成：1）自然语言理解(NLU)2）对话状态追踪3）规则学习4）自然语言生成(NLG)

有一些SOTA任务导向的对话系统使用的是端到端的设计达到了比流水线设计更好的效果。

ODD则通常被分为了三种：1）生成系统2）基于检索的系统3）集成系统

1）使用的是seq2seq模型将用户的消息和对话历史匹配一个可能之前没有出现在对话语料库中的response序列

2）则是从之前已经存在的回复集合中选择一个进行回复

3）用两种方法结合了生成方法和基于检索方法：i.检索到的回复与生成的回复进行比较，选其中最好的 ii.生成式的模型用来优化检索到的回复

1）2）优缺点：

生成式的系统可以产出灵活的且上下文相关的回复，然而有时却缺少相关性并且常常产出一些傻傻的回复

基于检索的系统可以从人类回复集合中进行选择，因此在语言表面级别上更有相关性。然而检索系统受限于整个回复数据集合的有限性，并且有时检索回复的内容显示出了很弱的上下文关联能力。

先前的对话系统综述除失去时效性外，其中大多数都没进行多角度的分析。

一些过时的说法如chi-chat dialogue systems已经被替换为了open-domain dialogue systems.

传统的基于规则的对话系统由于其易于实施，并且可以自然回复，使其流行于先前的产品中。然而该对话系统应用领域是局限的。

基于非神经网络的机器学习对话系统通常通过模板填充

> Template filling is an efficient approach to extract and structure complex information from text to fill in a pre-defined template. They are mostly used in task-oriented dialogue systems.

来管理具体任务。相较于基于规则的，由于对话流没有被预先决定，而具有更好的灵活性。但是，其在F1模板填充分数上分数并不高，并且由于模板的固定受限于应用场景和回复的多样性。

Most if not all的SOTA模型都是基于深度学习的。

除对话系统之外，NLP领域与对话相关的任务包括但不仅限于1.问题回答2.阅读理解3.	 Dialogue Disentanglement (对话解纠缠： 其目的是能够在多人对话场景下，将一个完整且复杂的对话从数据流中分离为多条基于相似主题的线程，以便每条单独的线程都与特定主题有关。 ) 4.可视化对话5.可视化Q&A

6.对话推理7.对话语义解析8.对话关系提取9.对话情感分析10.仇恨言论检测11. MISC检测, etc.

整篇survey的篇章结构如下

![1667301878678](论文精读.assets/1667301878678.png)

**对话系统中的神经网络模型**

介绍的模型有：1）CNN 2）RNN 3）Vanilla Sequence-to-sequence模型 4）Hierarchical Recurrent Encoder-Decoder(HRED) 5）记忆神经网络 6）注意力神经网 7）Transformer

8）Pointer Net and CopyNet 9）深度强化学习模型 10）Generative Adversarial Networks (GANs) 11）知识图谱增强的神经网络

**CNN:**

现今的前馈层仍有一些问题：i.前馈层或是多层神经网络的操作仅仅是模板匹配，无法考虑具体的数据结构 ii.多层神经网络的全连接机制导致了参数的爆炸，从而导致了泛化性方面的问题。早期版的CNN，LeNet即缓和了以上问题。CNN一般由：卷积层、池化(聚集)层、前馈层.

近年NLP领域对CNN的使用急剧增多，许多任务**将词作为基本单元**，短语、句子甚至是段落对于语义表示同样有用，于是CNN就成了理想的语言分级模型化的工具

CNN是很好的文本特征提取器，但不是理想的序列编码器。

[Conversational Word Embedding for Retrieval-Based Dialog System](papers\Conversational Word Embedding for Retrieval-Based Dialog System.pdf)直接使用CNNs作为语句或者知识的编码器，但是大多数SOTA对话系统比如[Span-ConveRT Few-shot Span Extraction for Dialog with Pretrained Conversational Representations](papers\Span-ConveRT Few-shot Span Extraction for Dialog with Pretrained Conversational Representations.pdf).选择使用CNNs来作为文本信息编码后的**分级特征提取器**，提取时有直接基于encoder输出的特征向量的，也有从字节级别的embedding提取的，比如[ Multi-Hop Paragraph Retrieval for Open-Domain Question Answering ](papers\Multi-Hop Paragraph Retrieval for Open-Domain Question Answering.pdf)

有一些基于检索的对话系统，使用不同的encoder去编码对话上下文和候选回复，之后用CNN作为从编码后的对话上下文和候选回复计算出的相似矩阵的提取器

现今工作不常用CNN作为对话的编码器是由于其不能连续灵活地提取跨越时序的时间步序列(即缺少跨度较大的相关信息)

CNN在处理序列时有两个局限性：1）其假设每个数据点都是相互独立的 2）其输入通常是定长的

HMMs隐马尔可夫模型是传统的序列模型，但由于其推理算法的时间复杂度以及状态转移矩阵随着各个状态空间的增加变得过于大，并不能使其具体应用于有着大规模可能存在的隐状态的问题。并且其隐状态仅受临近的隐状态所影响同样也限制了模型的能力。

RNN则很好地解决了这一问题

The inductive bias of recurrent models is non-replaceable in many scenarios

现今的RNN模型可被归类为两大类：
1）Jordan类型的2）Elman类型

以上简单的RNN在理论上是可以编码长周期的依赖信息的，但实际训练时缺难以被学到。梯度爆炸和梯度消失问题对于简单RNN来说非常常见。

于是出现了其各种改进版：LSTM、GRU、双向RNN、使用RNN的seq2seq

传统的seq2seq模型解码时使用的是当前隐状态和最后一个时间步的输出。最后一个时间步中并不能包含整个序列的信息。并且RNN不能将整个序列的信息编码到一个定长的隐状态向量中。

![1666428270273](论文精读.assets/1666428270273.png)

RNN大类的神经网络模型在基于神经网络的对话系统由于其编码序列信息的强大能力而充当着重要角色。

任务导向的对话系统将RNN作为**对话上下文**、**对话状态**、**知识库记录**、**领域标签**的编码器

开放域则将RNN应用于**对话历史**的编码器，其中包括基于检索系统的对话历史和候选回复。

在基于知识的系统中，RNN充当外**部知识源**的编码器(比如background、persona、topic, etc.)

RNN作为对话系统的解码器时通常将语句序列的隐状态使用贪婪搜索或者束搜索来进行解码。这种解码机制导致了一些比如万能回复的问题。

[RNN结合其他模型去训练对话embeddings](file:///D:/A/NLP/papers/NLG/A Contrastive Framework for Neural Text Generation.pdf).这些词嵌入模型在对话任务上进行训练，表现了更多的对话特性。在一些对话任务上其效果比未经在具体任务上微调的SOTA上下文表达模型(e.g., BERT, ELMo, and GPT)要好。

**HRED**(Hierarchical Recurrent Encoder-Decoder)

其设计的目的是感知历史查询

之后原作者又在解码器中引入隐变量使得解码步骤变成：1）采样隐变量 2）根据条件生成回复

最近很多工作使用了基于HRED的架构去捕捉多层级的对话特征。有认为标准的HRED将所有对话历史不加区分地进行处理。受Transformer架构影响，Vaswani等人提出ReCoSa，a self-attention-based hierarchical model.Shen等人提出了分三个层级的模型，包括1）篇章级 2）句对级3）句子级，分别捕捉全局知识、句对关键信息、内容信息。Chauhan等人使用HRED和VGG-19组合成为多模态MHRED，HRED编码层级对话信息，同时VGG-19提取对应轮次的所有视觉信息，并添加了一个位置感知的attention。Mehri通过四个子任务学习到了对话的上下文信息，其中的三个子任务(下句生成、掩码句子检索、不一致性识别)将HRED作为上下文信息的编码器。

Cao使用HRED编码患者和医师的对话历史以及客户端MI行为编码，并且预测未来的编码。

Qiu等人使用基于LSTM的VHRED去解决了在无监督数据中去归纳two-agent和multi-agent对话结构问题。除此之外他们在two-agent对话和一个非映射依赖树结构的multi-agent使用了Conditional Random Field model

**Transformer-based pretrain models for dialogue systems**

zhao等人使用一个综合性的数据集构建了一个基于知识的对话系统，该系统使用BERT进行知识的检索，使用GPT-2基于对话上下文和检索到的知识进行对话生成。

**Pointer Net and CopyNet**

在一些NLP任务中，比如对话系统和问题回答，智能体有时需要直接引用用户的信息，Pointer Net就解决了直接从用户输入中复制词元的问题

其对seq2seq模型中最后解码时

###### CopyNet

其提出是为了将copy机制融合进传统的seq2seq模型，由模型决定每个解码阶段是去从资源中复制还是生成资源中没有的新的词元。copynet的编码器与传统的seq2seq一样，解码器在预测时结合了生成模型和copy模型

![1667818723213](论文精读.assets/1667818723213.png)

>Where t is the time step. st is the decoder hidden state and yt is the predicted token. ct and M represent weighted sum of encoder hidden states and encoder hidden states respectively. g and c are generate-mode and copy-mode respectively.

copy机制适用于含有术语或者外部知识的对话，在基于知识的和任务导向的对话系统中广泛应用。

对于基于知识的系统而言，外部文件或者对话就是copy的源。

许多对话状态追踪任务使用a copy component生成槽和槽值

Pointer networks and CopyNet同样用于对话相关的任务，Yu 使用了一个pointer net用来在线对话解纠缠。指针模块指向当前消息所回复的祖先消息，之后使用分类器预测两条消息是否属于同一个线程。 在对话分析任务中，采用Pointer net作为主干分析模型来构建篇章树 

**Deep Reinforcement Learning Models and Generative Adversarial Networks**

近年来，强化学习在许多复杂问题上已经胜过了人类，比如大规模游戏、对话、车辆驾驶。另一个惊艳的技术是GAN，其在生成任务中表现出了惊人的能力，由GAN生成的一些如文章、绘画，甚至是视频已经能够以假乱真。

强化学习目的是训练智能体使其与具体环境交互时做出正确的决策，其是机器学习三大基础分支之一。

<img src="论文精读.assets/1667822621207.png" alt="1667822621207" style="zoom:50%;" />

强化学习的框架如上图，该框架是一个马尔可夫决策过程Markov Decision Process (MDP)，可以被描述为一个五元组M = （S, A,P, R, γ），其中S是一个无限的环境状态空间；A是智能体根据给定的环境状态s选定的动作集合；P是MDP中的转移概率矩阵，代表着智能体做出动作之后环境空间转移的概率；R是智能体在状态s下做出动作后从环境中获得的奖励；γ是折扣系数。该框架的运行遵循以下两步的循环：1）智能体首先观察当前的环境状态$s_t$，并且基于其策略选择一个动作；之后根据转移概率矩阵P，环境转台转移到$s_{t+1}$,同时产出一个回报$γ_t$

由于对话系统智能体-环境交互的本质，强化学习可用于解决该领域的很多问题. 对话系统通常由一个智能体即对话机器人,和环境,即用户或模拟用户

GAN网的架构如下:

<img src="论文精读.assets/1667823924729.png" alt="1667823924729" style="zoom:67%;" />

其包含了一个生成器和一个鉴别器, 训练过程可以被看作是他们之间的对抗:生成器尽力生成数据分布去蒙混过鉴别器,然而鉴别器试图去区分真实数据和生成的假数据.

在训练过程中,生成器将噪声作为输入,鉴别器则将真和假数据作为输入,并且以二进制注释作为标签

GAN网是一个特殊的actor-critic,其actor生成时具有盲目性,并且整个过程是一个不依赖状态的MDP

**RL for task-oriented dialogue systems**

RL被应用于对话管理中的对话状态追踪和策略学习,尤其在对话策略学习中近期的工作都是结合RL.这是基于策略学习的特点:模型基于DST模块去预测对话action,这就完美贴合了智能体在RL中的位置.

**RL for open-domain dialogue systems**

由于直接生成对话需要很大的动作空间,因此许多开放域对话系统使用RL来选择回复,而不是生成回复.基于检索的系统有着有限的动作集合,故适用于RL.

然而检索系统的回复并不能应付所有用户的消息,并且可能给出无关的回复.

Zhu等人选择结合检索和生成的方法来设计系统,首先检索一个长度为n的最优候选回复集合,然后再基于检索的结果和用户所发送的信息去生成.相较而言,Serban等人首先使用不同的对话模型生成并检索候选回复,然后在一个使用在线RL的打分模型去从生成和检索到的回复中选择回复

由于从零开始使用RL训练一个生成对话智能体时很困难的,因此首先将智能体进行监督学习去进行热启动是一个不错的选择.

**RL for knowledge grounded dialogue systems**

一些系统使用RL去选择一些外部信息,如角色信息 文档信息和知识图等,然后根据这些信息去生成回复

在强化学习框架中,智能体每一步基于当前节点和状态选择一条边,然后将知识结合进生成回复的过程中

**RL for dialogue related tasks**



**GAN for dialogue systems**

对话系统中GAN网的应用分为了两个流派, 第一种将GAN框架应用于增强回复生成.鉴别器区分人类的和生成的回复,GAN的生成器则用来生成更高质量的回复.另一个流派则是用GAN作为一个对话系统的评价工具.将生成器和鉴别器作为一个整体架构训练好后, 鉴别器被单独用来去给对话智能体进行打分,其打分结果与人工评分的相关性相比于BLEU, METEOR, ROUGE-L, etc. 都高

**2.8 Knowledge Graph Augmented Neural Networks**

使用带标注数据进行的有监督训练试图学到数据集中的知识分布.  然而一个数据集是相对稀疏的,因此要学到一个可靠的知识分布,需要大量的有注释的数据

###### Knowledge Graph (KG)

是一个由实体和它们之间关系组成的有结构的知识源. 换句话说, KG就是将知识呈现在图结构中.具体KG例子:

![1667893658660](论文精读.assets/1667893658660.png)

KG被存储在以来源描述为架构的三元组中, 其中Albert Einstein, University of Zurich和他们的关系可以表述为(Albert Einstein, Graduate From, University of Zurich)

知识图谱增强的神经网路首先将实体和他们的关系在低维空间中进行表示, 之后使用神经模型去检索图谱中的相关事实. 知识图谱表示学习可以被大致分为两类:1)基于结构的表示 2)语义丰富化的表示

1)使用多维向量去表示实体和关系.2)将语义信息结合进实体和关系的表示中

神经检索模型同样有两个主要方向:1)基于距离配对的模型2)语义配对模型

1)关注映射的实体间的距离 2)计算实体和关系与检索事实间的语义相似度

**Knowledge graph augmented dialogue systems**

基于知识的对话系统可以从KG中的结构化知识大大获益, KG中的事实广泛地相互关联. 通过KG去推理是一个将常识知识结合到回复的生成中的一个理想方法.

##### ***3 Task-oriented Dialogue Systems***

任务导向的对话系统包括**1)模块化的**和**2)端到端的**系统

任务导向系统解决的是具体领域的具体问题,比如预定电影票, 预定餐馆等. 

**模块化系统**

任务导向系统需要更为严格的回复限制, 因为其目的是精确解决用户信息. 因此模块化方法的提出是为了以更为可控的方式去生成回复. 基于模块化的系统架构如下:

![1667905738951](论文精读.assets/1667905738951.png)

###### Natural Language Understanding (NLU)

该模块负责将用户的原始消息转换为**语义槽**[slot], 同时给出**领域分类信息**[domain]和**用户意图**[belief state]. 而最近的一些工作选择越过该过程, 直接使用原始用户消息作为下个模块的输入(上图中有表示出). 这样的设计是为了<u>减少模块间传播的错误, 并且缓解原始错误的影响?</u>

###### Dialogue State Tracking (DST)

该模块基于当前的输入和对话历史迭代式地矫正对话状态. 对话状态包括相关的**用户动作**和**槽值对**.

###### Dialogue Policy Learning

基于由DST矫正了的对话状态,该模块决定对话智能体的下一个动作.

###### Natural Language Generation (NLG)

该模块负责将选中的对话动作转变为语言表达, 即通常为最后的回复.

其中DST和DPL共同组成Dialogue Manager(DM), DM即为任务导向对话系统的中心控制器. 通常, 任务导向系统也与一个外部知识库(external Knowledge Base)进行交互, 去检索关于目标任务的重要信息. 比如在预定电影票的任务中, 在理解用户的需求后, 智能体就可以去电影知识库在相关限制下去搜具体的电影.

###### 端到端系统

模块化对话系统存在两个大的弊端:

1) 流水线中的有些模块有时候是不可微的, 这就导致末端的损失不能传达至每个模块. 真实的对话系统训练, 通常唯一的信号就是用户的回复, 而其它的监督信号像是对话状态, 对话动作是很少的.

2) 虽然各模块联接起来使得整个对话系统有出色的表现, 但单独某个模块的提升可能并不会使整个系统的对话精准度得到提升. 这会导致其他的模块进行额外的训练, 该训练是费时费力的. 

除此之外, 由于流水线中的一些手工定义的特征比如, 对话状态, 使得模块化系统很难迁移到另一个领域, 即预定义的一些东西需要进行修改.

任务导向的对话系统实现端到端的训练有两个主要方法:

1)使得流水线中每个模块都可微, 之后整个流水线就可以被视为一个大的可微的系统, 从而其中的参数可以由反向传播来优化.

2)仅使用一个端到端的模块去进行知识检索和回复生成, 这通常是一个**多任务学习**的神经模型

展开1）：

虽然大多数模块已容易变得可微，但知识数据库查询这个任务的可微仍是个挑战。许多TOD都需要利用外部知识源去检索到用户所需要的知识事实。比如在餐馆预定的任务中，知识事实就可以是一个用来填充slot的具体餐馆。传统的方法是根据实体的特征使用符号查询来进行匹配。系统负责对用户的消息进行解析，并根据用户的意图去表示出一个符号查询。然而该检索过程是不可微的。

之后出现的key-value记忆网络即使用key-value检索机制检索相关事实。该架构可以使用注意力机制去计算对话中语句表示和知识数据库中key表示的相关性。

[软检索机制](paper/)使用了一个对知识库的软的后验分布代替符号查询，并且将软检索机制与RL架构结合，实现了基于用户反馈的端到端的训练。

Hybrid Code Networks将领域内具体的知识编码进了软件和系统动作模板，实现了检索模块的可微。该工作没有直接编码对话状态，而是学习了隐藏表示，并使用监督学习和RL优化了HCN

[Ham et al.](papers/End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2.pdf)使用GPT-2构建了一个包含领域预测、对话状态追踪、策略学习、知识检索、回复生成的流水线。[ A Simple Language Model for Task-Oriented Dialogue ](papers/A Simple Language Model for.pdf)同样使用GPT-2构建了一套为各个模块进行生成的流水线。

展开2）：

近期的工作都偏向于构建一个复杂的神经网络模型将所有模块的功能集成到一个。端到端的TOD模型要么关注**训练的方法**，要么关注于**模型的架构**，这两点即是回复质量与正确性的关键因素。

[Wang et al. (2019a)](papers/Incremental Learning from Scratch for Task-Oriented Dialogue Systems.pdf)提出加性学习框架(incremental learning framework)去训练端到端的TOD，其主要想法是使用了一个不确定性估算模块去评估所回复生成的置信度。当回复的置信度高于阈值时，该回复将会被接受，否则将使用人工回复。智能体也能够通过在线学习习得人类的回复。

[Dai et al. (2020) ]()使用模型无关的元学习(model-agnostic meta-learning (MAML) )利用少量的训练数据在现实场景的在线服务任务下提升模型的适应性和可依赖性。

[Qian and Yu (2019)]()同样使用MAML方法来帮助模型适应新领域，使模型首先在富资源的任务上进行训练，然后在新任务上使用有限数据训练。

[Lin et al. (2020c)]()提出的温和迁移学习Minimalist Transfer Learning (MinTL)通过使大规模预训练模型即插即用来实现领域的迁移。

为了保证所生成回复序列的正确性[Wu et al. (2019b)]()在无监督方法下训练了一个不一致顺序检测模块，用来检测句子对是否有序，来指导生成任务生成更为连贯的回复。

[He et al. (2020a)]()提出了一个“Two-Teacher One-Student"框架。在第一个阶段，两个teacher模型在RL框架下分别以检索知识和生成human-like的回复为目标进行训练。第二阶段，student网络被强制去模拟teacher网络的输出。从而将两个teacher网路的知识迁移到student网络中。

[Balakrishnan et al. (2019) ]()提出了一个限制性编码方法去提升生成回复的语义正确性。

大多端到端的TOD都是用一个记忆模块来存储相关的知识事实和对话历史。

[Chen et al. (2019c) ]()认为单个记忆模块无法提供精准的检索，因此他们使用了两个长周期的记忆模块分别存储相关知识元组和对话历史。之后使用working memory来控制token的生成。

[Zhang et al. (2020)](papers/A Probabilistic End-To-End Task-Oriented Dialog Model with Latent.pdf)提出了LAtent BElief State (LABES)模型将对话状态视为离散的隐变量从而减少对于轮次级别的DST标签的依赖。

[Gao et al. (2020a)]()使用一个解释模块增强了回复生成。该paraphrase模块与整个框架联合进行训练，其目的是增强训练样本。

[Yang et al. (2020)](papers/(GraphDialog)Integrating Graph Knowledge into End-to-End TODS.pdf)利用了知识图和对话上下文依赖树中的图结构信息。他们提出了一个循环的cell架构去学习图上的表示，并进行多条推理来挖掘知识图中实体的联系。通过对图知识的增强，该工作在两个TOD数据集上得到了提升。

###### **3.6 Research Challenges and Hot Topics**

- Pretrained Models for NLU

  

- Domain Transfer for NLU

  

- Domain Transfer for DST

  

- Tracking Efficiency for DST

  

- Training Environment for PL

  

- Response Consistency for NLG

  

- End-to-end Task-oriented Dialogue Systems

端到端的TODS往往是数据驱动的，数据量足够大才能保证回复的自然和鲁棒性。但是由于带标记训练数据的有限性，一个研究热点就是怎样使用有限的数据来提高端到端TODS生成回复的质量. 

使用**基于规则的方法**能通过限制回复的方法来提升回复的质量:

[Balakrishnan et al. (2019)]()使用线性化的树结构表示作为输入来掌握篇章级和句子级的概念.

[Kale and Rastogi (2020)]()使用模板来提升生成回复的语义正确性, 该工作将回复生成分为了两个阶段.第一阶段:基于槽值且在模板的限制下生成语义上正确但是可能不连贯的回复.第二阶段:预训练语言模型被用来去重新组织这些回复,使其变得连贯.

使用**RL的方法**去训练网络也是用来缓解对带标记数据依赖性的一个方法.



一个更为直接的解决数据量不够问题的方法就是**扩充数据集**.[(Elder et al., 2020)](papers/How to Make Neural Natural Language Generation as Reliable as Templates in TOD.pdf)

另外在常识数据集上进行预训练然后将其应用到缺少带标签数据的领域是近年来流行的方法.[Bao et al., 2019b](papers/(PLATO)Pre-trained Dialogue Generation Model with.pdf)

##### *4 Open-Domain Dialogue Systems*

开放域对话系统是没有具体任务和领域限制的情况下与用户进行闲聊, 通常是数据驱动的.开放域对话系统通常分为三大类:1) 生成式系统 2) 基于检索的系统 3) 集成系统

1) 使用seq2seq的模型, 为用户信息和对话历史配对到一个可能在训练数据集中没有出现过的回复.

2) 则想去找到在确定的回复集合中已经存在的回复

###### some research challenges and hot topics in open-domain dialogue systems

**Context Awareness**

对话上下文包括用户消息和系统消息，由于该信息决定了对话的主题和用户意图，因此是对话智能体产生回复的重要信息来源。具有上下文感知能力的对话智能体在生成回复时应能够结合当前用户消息和上下文去给出回复。先前的基于深度学习的系统将所有对话历史的单词表示直接累加，或者以一个固定大小的窗口去聚焦近期的上下文。Serban等人提出了Hierarchical Recurrent Encoder-Decoder (HRED)，该工作为上下文感知领域开创性的工作。



不论是生成式的还是检索式的对话系统，都对对话上下文建模具有很高的依赖性。shen等人提出了Conversational Semantic Relationship RNN (CSRR)从三个级别去建模对话的上下文：1）语句级别 2）句对级别 3）篇章级别 分别去捕捉内容信息、用户主题、全局主题。zhang指出分层的encoder-decoder在decoder与对话上下文交互时没有很好地强调其中具体的部分。

Feng等人的工作中，不仅利用了对话历史，也用了未来的对话。考虑到在现实的推理中，对话智能体不能明确地知道未来的信息，他们首先使用过去和未来的上下文训练了一个基于场景的模型，然后用了一个仿真框架将场景知识迁移给目标网络。

**Response Coherence**

回复相关性是指对话能够保持逻辑和一致性

**Response Diversity**

**Speaker Consistency and Personality-based Response**

**Empathetic Response**

**Controllable Generation**

**Conversation Topic**

⑤相关工作

⑥模型

⑦实验

⑧评论

---

### 4.GAN

<a name='d4'>-</a>

①标题+作者

②摘要

③结论

④导言

深度学习是用来发现丰富的有层次的模型来表示AI中各种应用的各种数据的概率分布表示。深度学习目前在辨别模型上做的比较好，但是在生成模型上还是比较差 ，这是由于在最大化似然函数时需要对其概率分布进行很多近似，这个近似带来了很大的计算困难。GAN则选择不去近似这个似然函数，而是去学习一个模型去近似这个分布

⑤相关工作

⑥模型

⑦实验

⑧评论

---

### 5.UniDS

<a name='d5'>-</a>[原文](papers/UniDS A Unified Dialogue System for Chit-Chat and Task-oriented Dialogues.pdf)

①标题+作者

A Unified Dialogue System for Chit-Chat and Task-oriented Dialogues

中国科技大学和华为诺亚方舟实验室联合Huawei Noah’s Ark Lab

②摘要

③结论

④导言

⑤相关工作

⑥模型

第t轮的对话的组成成分包括：用户输入$U_t$，对话状态$B_t$,数据库搜索结果$D_t$，系统动作$A_t$，以及回复$R_t$，其中的每个成分都由来自定长词典的词元组成。对于每一轮t，给定$$C_t$$作为对话上下文信息$C_t=[U_0,B_0,D_0,A_0,R_0,……,R_{t-1},U_t]$

首先会根据上下文信息$C_t$去生成对话状态即用户意图的概率分布
$$
B_t = UniDS(C_t) ,
\tag{1}
$$


然后根据对话状态去搜索数据库，获取到搜索结果$D_t$。Afterwards，UniDS生成系统动作$A_t$，该动作由扩充后的上下文信息(新加入了$B_t$、$D_t$)所决定
$$
A_t = UniDS(C_t ⊕ [B_t,D_t])
\tag{2}
$$
最终生成回复
$$
R_t = UniDS(C_t ⊕ [B_t,D_t, A_t])
\tag{3}
$$
UniDS架构如下：

![1668667790524](论文精读.assets/1668667790524.png)

为了使得闲聊和任务导向对话数据能同时进行有效的训练，本文设计了一个统一的数据规范：

![1668669582727](论文精读.assets/1668669582727.png)

有了该标准后，第t轮的数据的输入不论是TOD还是ODD都得到了统一的表示：
$$
X_t = [C_t, B_t,D_t, A_t, R_t]
\tag{4}
$$
UniDS的训练目标就是通过自回归的方式最大化$X_t$中所有tokens的联合概率
$$
l=\sum_{i=1}^N-logP（x_i|x_{<i}）
\tag{5}
$$





$$
l_w=\sum_{i=1}^N-w_ilogP（x_i|x_{<i}）
\tag{6}
$$




⑦实验

⑧评论

---

### 6.ConvLab-2

<a name='d6'>-</a>[原文](papers/ConvLab-2.pdf)

①标题+作者

An Open-Source Toolkit for **Building**, **Evaluating**, and **Diagnosing** Dialogue Systems

②摘要

ConvLab2是用来帮助研究者使用当前的SOTA模型来构建任务导向对话系统的工具，可以实现端到端的测评，并且能够诊断系统的缺点。提供了一个分析工具和一个交互工具来诊断对话系统。分析工具可以通过模拟对话后展示大量的数据统计，和常规错误的总结，有助于错误分析和系统的提升。交互工具提供了用户界面，开发者可以通过与集成的对话系统进行交互，并且修改每个系统的构件。

③结论

④导言

⑤相关工作

⑥模型

⑦实验

⑧评论



---

### 7.UBAR

<a name='d7'>-</a>[原文](papers/UBAR Towards Fully End-to-End Task-Oriented Dialog Systems with GPT-2.pdf)

①标题+作者

$U_t、B_t、A_t、R_t$

Towards Fully **End-to-End** Task-Oriented Dialog System with **GPT-2**

②摘要

UBAR是任务导向的会话级别的对话模型，是从单向语言模型GPT-2在成序列的整个会话(每轮都包括用户语句、会话状态、数据库查询结果、系统动作，系统回复)微调得来的。UBAR是在更为实际的配置下进行评估的，其对话上下文可以访问到用户的输入，以及所有生成的内容，such as belief states, system acts, and system responses。在MultiWOZ数据集上的结果显示UBAR达到了SOTA水平，提高了回复的综合评分4.7个点，策略学习下3.5，端到端情况下9.4。



③结论

④导言

先前一些尝试端到端生成的任务导向的对话系统，有的使用基于事实的belief state，有的将多个模块使用不同的decoder进行生成。

有的利用大规模预训练模型去生成belief state，并且将数据库的查询结果也纳入进了训练过程中。但其训练和评估过程仍没有面向现实应用场景的任务导向对话去设置。具体而言，其训练评估是对话轮次级别的，而不是对话会话级别的，这使得其有一定局限性。

首先这些方法的对话历史信息仅包含了用户输入、系统回复，而没有包含中间的各种信息(先前轮次的belief states、system acts)

其二，它们使用从对话历史注解中获得的ground truth的回复，这使得某个对话轮次的生成独立于了整个会话中的其他轮次。

最后，真实应用场景中假设能获得到完全正确的系统回复是无效的



⑤相关工作

###### Towards End-to-End Task-Oriented Dialog

先前的DST方法都是通过分类任务进行，对话状态被表示为了一个对于每个槽可能的状态的分布。

为了提升泛化性追踪到一些未知的槽值和多领域的配置，生成式的方法提出了为DST抽取槽值

同样的对于对话策略学习，系统动作通常被编码成向量表示，比如one-hot，并用于回复的生成。

之后DST的结果和系统Action将与系统的回复联合进行训练。[Multi-Domain Dialogue Acts and Response Co-Generation](papers/Multi-Domain Dialogue Acts and Response Co-Generation.pdf)

对于端到端的建模[Lei et al. (2018)](papers/(Sequicity)Simplifying Task-oriented Dialogue Systems with Single Seq2seq Architectures.pdf)提出了一个分两个阶段的CopyNet，其使用一个seq2seq架构同时生成belief span和系统回复

[Zhang, Ou, and Yu (2020)](papers/Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context.pdf)提出了一个领域感知的多解码器模型，其使用不同的解码器去生成belief pans、act spans和回复。

还有一些利用GPT-2来实现端到端的.比如[simpleTod](papers/A Simple Language Model for TOD.pdf)、[SOLOIST](papers/(SOLOIST)Building Task Bots at Scale with.pdf)

> SimpleTOD (Hosseini-Asl et al. 2020) incorporates the database results into the training process and is evaluated for end-to-end modeling where belief state and system act are generated
>
> SOLOIST (Peng et al. 2020a) follows a pre-train and fine-tune paradigm where it first undergoes pre-training on a large number of out-ofdomain dialog turns, then fine-tune on the data of new domains.

除此之外直接操作对话历史与知识库交互无需任何中间监督的方法也开始出现。[global_to_local_memory_pointer](papers/global_to_local_memory_pointer.pdf)、[Mem2Seq](papers/(Mem2Seq)Effectively Incorporating Knowledge Bases into End-to-End TOD.pdf)、[Key-Value Retrieval Networks for Task-Oriented Dialogue](papers/Key-Value Retrieval Networks for Task-Oriented Dialogue.pdf)

⑥模型

###### Modeling on a Dialog Session Level

对于给定的包含有多轮对话的会话集合，UBAR处理的具体方式如下：

在第一轮t=0时，用户输入$U_0$，UBAR基于$U_0$生成belief state$B_0$，该belief state用来查找数据库去检索与state中相匹配的实体，最终获得数据库查询结果$D_0$。根据$\{U_0, B_0,D_0\}$ UBAR会生成系统动作$A_0$,以及一个非虚化的回复$R_0$,至此完成第一轮交互。当对话进行到第t轮时，UBAR将基于先前所有生成的信息$\{U_0, B_0,D_0, A_0, R_0, ..., U_{t−1}, B_{t−1},D_{t−1}, A_{t−1}, R_{t−1}, U_t\}$去生成$B_t$、$A_t$和$R_t$，直到完成整个会话。因此单个有T轮对话的会话的训练序列可以表示为$\{U_0, B_0,D_0, A_0, R_0, ..., U_T, B_T,D_T, A_T, R_T\}$

需要注意的是不同于之前的方法，以轮次级别基于$\{U_0, R_0, ..., U_{t−1}, R_{t−1}, U_t\}$去生成第t轮的回复，并且先前工作在历史对话中的回复信息是ground truth的。而UBAR将中间信息$B、D、A$一同纳入到了上下文信息中。

###### Domain-Adaptive Pre-processing

delexicalizing the responses并将中间对话信息转换为spans。所有序列都被特殊符号$<sos\_?>、<eos\_?>$所包绕用来标识开始和结尾，其中$?$对应着具体的{u, b, db, a, r}.下图为处理后的训练序列：![1669532878113](论文精读.assets/1669532878113.png)



###### Delexicalization

TOD生成虚词化的回复可以使模型学到与具体的值无关的参数。虚词通过其对应的占位符替代具体槽值，这可以根据数据库搜索的结果去填充这些虚词。For example, a hotel name in the generated response is just <value name> instead of <hotel-value name>.

###### Belief State and System Act Spans

Belief states原本是表示为(domain-slot，value)对的形式，UBAR将领域domian和槽slot进行了分离，来使得不同的领域能够共享相同的知识。

一个有两个相关联领域的belief state可以表示为{[domain1] slot value slot value [domain2] slot value}。每个domain都可以根据用户的意图跟几个槽值对。

对于数据库的查询结果，使用了特殊符号去表明在当前轮次belief state的限制下所匹配的实体的数量。

系统动作原本被表示为(domain-act,slot)对，用来通知或请求与具体领域相关的信息。该表示在UBAR中同样被分离为了{[domain] [inform] slot ... [request] slot ...}，将领域分离开来的方法可以使得对话知识和表示能够跨领域地学习到。

domains、acts、slot values都作为额外的特殊符号纳入到输入序列中，因此可以被学习到。



###### Architecture and Training Objective

UBAR是在GPT-2的基础上进行的微调

⑦实验

验证UBAR的知识跨领域迁移能力时，使用UBAR在已知五个领域中的四个上进行训练得到基础模型。在零样本微调下，模型的表现随领域不同有所波动，火车领域达到了最高的综合分数，餐馆领域却表现很差。这是由于火车领域本身就与其他领域有高度的知识重叠，而餐馆却有着单独的food槽被反复提及

![1668946425182](论文精读.assets/1668946425182.png)

该表中UBAR在所有领域上训练后的结果与在基础模型上对新领域进行微调后的结果的巨大差距表明了，端到端的任务导向模型数据驱动性的本质。

⑧评论

### 8.InstructGPT

<a name='d8'>-</a>[原文](papers/InstructGPT.pdf)

①标题+作者



②摘要

③结论

④导言

语言模型应该是: **helpful**(帮助用户完成任务)、**honest**(不能编造虚假信息或者误导用户), and **harmless**(不能对人和环境造成身体上、心理上或者社会上的伤害)

the language modeling objective used for many recent large LMs—predicting the next token on a webpage from the internet—is different from the objective “follow the user’s instructions helpfully and safely”

⑥模型

⑦实验

⑤相关工作

⑧评论

chatGPT中多轮对话的能力是如何具备的？

因为codex代码数据增加了其长程的推理能力?

Limitations：

方法上：对prompt进行答案标注和答案质量排序时受雇员个人主观因素影响大。
训练数据中几乎全是英文，并且雇员都是English-speaking，这也是必然影响多语种使用的问题。

模型上：该模型生成的消息并不完全能与用户要求达到一致，也不足够安全，仍然有偏见、恶毒的回复



由大模型引出的新的研究题目：

找到更为系统的提示方法、如何更正错误->Neural Editing、AI生成内容侦测、防止泄密->Machine Unlearning

## 医学领域对话

### 1.AI Doctor

<a name='md1'>-</a>[原文](papers/The AI Doctor Is In A Survey of Task-Oriented Dialogue Systems for Healthcare Applications.pdf)

①标题+作者

The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications

 伊利诺伊州芝加哥分校 NLP实验室

②摘要

本文通过对70篇医疗领域任务导向对话系统的回顾，提出了所发现的差距以及相关建议。

③结论

④导言

 目前在对话系统的前沿、基础工作和医疗保健环境中的原型或部署的对话代理之间仍然存在差距 。本文旨在通过调研现存的医疗对话系统来解决该差距。

本文调研了a）现存系统如何应用 b）调研系统特点、缺点以及future work

贡献如下：

1. 找出了70篇符合本文标准的工作
2. 基于系统目标、语言、架构、形式、设备类型和评价范式分析这些系统
3. 找出了这些系统的局限性包括：对于模型架构的不充分利用、复现问题、道德和隐私问题，并对可用性和用户粘性进行了少量调查。本文提供了解决以上问题的建议作为future work的切入点。

⑤相关工作

本文挑选的论文符合：

- 焦点必须在TODS的应用或者技术设计上
- 必须是健康相关的系统
- 不能只关注于对话系统的某个模块

⑥Ontology

本文将所选文章按照**domain of research** (§4.1), **system objective** (§4.2), **target audience** (§4.3), and **language** (§4.4)进行了讨论



**domain of research**
大类包括：mental health, physical health, health information, patient assistance, physician assistance, cognitive or developmental health, and other (comprising subcategories not easily classifiable to one of the broader domains)

<u>心理</u>、<u>认知</u>、<u>身体</u>健康问题

mental health, physical health, and health information were the most prevalent, covering 51 of the 70 included papers.

![1670562283727](论文精读.assets/1670562283727.png)

**system objective** 
![1670399402419](论文精读.assets/1670399402419.png)

多目标系统中大多都是既能诊断又能为用户提供帮助。
本文同样考虑到用户粘性**engagement**([MEDCOD](papers/MEDCOD.pdf))作为每个系统潜在的目标，即能够吸引用户与系统进行交互。
用户的参与度在医疗保健背景下非常重要，因为这影响着用户最终是否会采纳系统所给出的建议。(Montenegro et al., 2019)

>Surprisingly, almost 60% of the papers (41 of the 70 surveyed) did not mention any goals pertaining to engaging users in more interactions.

**Target Audience**
![1670400657170](论文精读.assets/1670400657170.png)

**Language**

![1670400926253](论文精读.assets/1670400926253.png)

⑦System Architecture

![1670401165808](论文精读.assets/1670401165808.png)

绝大多数使用模块化(NLU->DST->DPL->NLG)
极少数使用端到端方案，即只用一个模块解决所有问题。

**Dialogue Management Architecture**

不同于其他pipeline中的模块，DM不影响用户体验和粘性而是提供核心的决策，即为核心模块。

大致分为了：1）基于规则 2）基于用户意图 3）混合方案 4）基于语料库

1）的成功与否在于预定义的规则是否涵盖了搜有的案例。
2）则旨在从对话中抽取用户意图
3）混合1）2）
4）利用人与人的对话数据，通过检索或者生成式的方法进行回复

![1670416869788](论文精读.assets/1670416869788.png)



⑧System Design

**Modality**，即人机交互的途径
![1670417378180](论文精读.assets/1670417378180.png)

**Device**

![1670417481166](论文精读.assets/1670417481166.png)

数据方面，少数文章将数据公布，并且其中数据经审核通过的更少。

**系统评价**

通常以问卷调查或者直接反馈的方式进行人工评测，该方法具有很强的主观性。

相比之下自动化评估方法具有客观性，从数学的角度对系统进行1到多个维度的定量评测。

![1670425254573](论文精读.assets/1670425254573.png)

评测人员情况：

![1670425461556](论文精读.assets/1670425461556.png)

评测方式：

![1670425485875](论文精读.assets/1670425485875.png)

评测指标：

![1670425521811](论文精读.assets/1670425521811.png)

⑧Discussion

**Incomplete Exploration of System Design**

系统级别架构同质化严重，几乎都采用pipeline架构。

---

### 2.DIALMED

<a name='md2'>-</a>[原文](papers/DIALMED-A Dataset for Dialogue-based Medication Recommendation.pdf)

①标题+作者

A Dataset for Dialogue-based Medication Recommendation 基于对话的药物推荐数据集
一作浙江大学 Zhenfeng He, Yuqiang Han

②摘要

先前药物推荐所使用的主要是EHRs(electronic health records)电子病历。而然医生与病人之间交流的细节往往在EHRs中被忽略，而这些被忽略掉的信息往往也是对药物推荐具有很大作用的。
本文构建的DIALMED是第一个高质量基于医疗对话的药物推荐数据集。

>It contains 11, 996 medical dialogues related to 16 common diseases from 3 departments and 70 corresponding common medications.

同时本文也提出了一个Dialogue structure and Disease knowledge aware Network (DDN)，其中QA对话图机制被用来建模对话结构，知识图被用来引入外部疾病知识。

③结论

④导言

本文发现大约 31%的用户，咨询的都是问自己当前的病情适合吃什么药。下图为常见的药物咨询对话：

![1670489326871](论文精读.assets/1670489326871.png)

QA对话图用来理解句子中隐含的Q&A，之后对QA图使用graph attention network获取对话嵌入。同时对于输入的疾病，将在知识图CMeKG中进行检索，并且将对话嵌入输入到graph attention network 获取上下文的疾病嵌入。最终将两个嵌入融合，来进行药物预测。

contribution：

- 构建了第一个高质量的人工标注的用于药物推荐的对话数据集。
- 提出了新的药物推荐架构，使用QA Dialogue Graph建模了对话结构，并且引入了外部疾病知识。
- 进行了大量实验来证明DDN可以抽取重要信息来使得药物推荐更加高效。

⑤相关工作

**Medication Recommendation**

由于隐私问题，获取患者在网络平台的历史对话信息非常难，因此本文只是基于本轮会话去进行药物推荐。

**GNN**

近期有工作将GAT用来进行对话建模。(Chen et al., 2020)使用图注意力和循环GAT去编码对话语句，schema graphs和先前的对话状态用来做对话状态追踪。(Qin et al., 2020) 提出了一个相互交互的GAT层去同时解决对话动作识别dialog act recognition和情感分类任务。本文使用GAT去建模讲话者自身和讲话者之间的相关性去在QA对话图上传播语义，并通过知识图引入外部知识扩展了GAT

#### Corpus Description

###### Construction Details

本数据集收集自春雨医生(网络问诊平台)，由于被诊断的疾病和症状对于药物推荐来说都十分重要，并且考虑到症状的复杂性，本文采用**explicit disease** and **implicit symptoms**。具体数据标注：
we annotate the disease Upper Respiratory Tract Infection, and replace the medications Shuanghuanglian Oral Liquid and Pudilan Oral Liquid with special token [MASK].

数据标注分两步：对药物和疾病进行1）标签化 2）规范化

1）中选用的数据是16种常见疾病进行标注，并且药物对应三种科室(呼吸、肠胃、皮肤)的常见药物，由三位有医学背景的标注员来完成工作。

2）按照DXY Drugs Database、ICD-10对药物和疾病的名称进行了规范化

###### Dataset Statistics

相较其他，本对话数据集的优势：1）手工标注的最大的医疗对话数据集 2）平均对话论数较多 3）精选了适合做药物推荐的领域来制作

###### The comparison with other studies

DIALMED是首个基于医疗对话的药物推荐数据集。

**Dataset**

由于进行了规范化，因此不会出现像其他数据集将Omeprazole entericcoated tablet, Omeprazole tablet and Omeprazole归为三种类别的情况

**Task**
药物推荐是医学诊断的子任务。根据患者的问题，诊断系统目标是生成出最优的临床回复，该回复包括有问候、询问或诊断。药物推荐是其中的核心任务，并且需要专门的数据集。

**Scenario**
DIALMED，与当前药物推荐研究所使用的EHR数据集MIMIC-III有很大不同。前者的情景是门诊流程，后者则是由ICU中数据生成的。MIMIC-III中药物的数量是145种，每次访问中涉及的药物有8.8种，涉及的诊断有10.51种。相比之下，医疗对话中的标签是相对稀疏的。

⑥模型

![1677068545951](论文精读.assets/1677068545951.png)

解决的问题：将就诊对话D和诊断的疾病d作为输入，基于对话的药物推荐目标是推荐M中潜在的治疗药物y

模型总览：整体为end-to-end架构。具体包括两部分：1）**对话编码器**，通过捕捉对话语义信息和结构来编码MEDIAL 2）**疾病编码器**，从对话和知识图谱中融合进外部医疗知识

###### QA Dialogue Graph

医学对话中医生患者的对话大多都以Q&A方式进行，因此在对话中捕捉Q&A对结构非常有助于理解整个对话。本文的QA对话图即用来构建该结构。

图中的1）一个节点表示一个句子2）连续的由同一个人说的句子被表示为一个块

![1677055431434](论文精读.assets/1677055431434.png)

图中u2、u3组成一个两个节点构成的block，u4单独构成一个单节点块

节点之间边的限制：
1）在一个块内，每个节点用边进行连接。这表示intra-speaker联系，确保来自同一说话者的信息在本地上下文中的话语之间传播

2）相邻的块之间，块内的每个节点连接到其他块中的所有节点。这表示inter-speaker联系这确保了在连续的语境中医生和患者之间的信息流动 

该QA图相较于先前对话编码方式的优点：1）图的构建不需要额外的监督信息 2）可以全面地捕捉到QA对的**结构**和**语义**信息，也即理解对话的关键

###### Dialogue Encoding

GAT用来自动整合QA对话图的语义和结构信息。

###### Disease Encoder

本文从**CMeKG**(高质量中文医学知识图)中纳入了疾病知识。TransR用来初始化实体embeddings。
对于给定疾病d，首先定义CMeKG中对应的实体，然后从该疾病开始的K跳知识图子集将被随机取样出来，最终GAT在对话语境下得到疾病embedding

###### Model Inference and Optimization

对话、疾病的词嵌入使用fusion fuction进行拼接来预测

$y = σ(Wo[h_D; s_d] + bo)$

⑦实验

⑧评论

### 3.On the Generation of Medical Dialogs for COVID-19

<a name='md3'>-</a>[原文](papers/On the Generation of Medical Dialogs for COVID-19.pdf)

①标题+作者

  [ACL/IJCNLP (2) 2021](https://dblp.uni-trier.de/db/conf/acl/acl2021-2.html#ZhouLTZYHJCCYZW20) CCF-A类会议

②摘要

疫情导致COVID19-related 在线 consultations需求增加。本文收集了两个对话数据集CovidDialog

>(in English and Chinese respectively)containing conversations between doctors and patients about COVID-19

相较于通用领域对话数据集，本文所收集的数据量小很多。因此在训练对话生成模型时面临着过拟合的问题。为了缓解这一问题，本文提出了**多任务学习**方法，即使用一个带掩码的token的预测任务充当低资源对话生成任务的正则项。

③结论

④导言

contributions：

- We collect two medical dialog datasets about COVID-19: one in English, the other in Chinese.
- We develop a multi-task learning approach, which uses a masked-token prediction task to regularize the dialog generation task to alleviate overfitting.
- We evaluate our method on the collected COVID19 dialog datasets and the results demonstrate the effectiveness of our method.

⑤相关工作

[Wei et al. (2018)](papers/Task-oriented Dialogue System for Automatic Diagnosis.pdf)基于强化学习的进行医疗自动诊断的对话系统
[Xu et al. (2019)](papers/End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis.pdf)知识路由的关系对话系统， 在对话管理中，将医学知识图集成到话题转换中 

⑥模型

⑦实验

⑧评论

### 4.Task-oriented Dialogue System for Automatic Diagnosis

<a name='md4'>-</a>[原文](papers/Task-oriented Dialogue System for Automatic Diagnosis.pdf)

①标题+作者

一作[复旦大学自然语言处理实验室](https://nlp.fudan.edu.cn/28695/list.htm)的Qianlong Liu

 魏忠钰老师团队

 发表在**ACL Short 2018** 

②摘要

本文首先从网络医学论坛上抽取了患者自我报告和医患对话中的各种症状，建立了数据集。

之后提出了任务导向对话系统框架，为病人提供自动诊断功能。该对话系统可以通过与病人对话，收集除其自我报告的病症之外的额外症状。

③结论

本文提出了基于强化学习的自动诊断的医疗对话系统，并且使用真实场景下的医生和患者的对话去训练对话系统。

疾病和症状之间是一种外部知识的关系，因此将**外部知识**引入策略学习中将会是未来的研究方向。

④导言

EHR(each EHR contains multiple types
of data, including personal information, admission note, diagnose tests, vital signs and medical image)被广泛用于疾病的自动诊断，但其构建成本高，因此需要一个用于方便收集患者症状的自动化方法。因此本文提出使用医疗对话系统去收集。

将对话系统应用到疾病识别的困难：
1）缺少带标记的对话数据集。2）没有现成的用于疾病识别的对话框架

Contributions are two-fold:
1）制作了第一个带标签的医疗对话数据集，该数据集包含患者自我报告和医患对话两部分。
2）提出了一个基于RL的医疗对话系统框架。

对话数据集经过Symptom Extraction—》Symptom Normalization 最终保留了67个高频症状。处理完后的数据被称为*user goal*

![1671003007162](论文精读.assets/1671003007162.png)

⑥模型

任务导向对话系统通常包括三个组成部分，NLU、DM、NLG。NLU负责检测句子中用户意图和slot-value对；DM追踪对话状态并且生成系统动作；NLG对于给定的系统动作生成对应的NL。

**本文关注于用于自动诊断的DM模块**，该模块由两个子模块组成：1）对话状态追踪（DST
2）对话策略学习（DPL）

**NLU、NLG都是使用的基于模板的方法。**

###### User Simulator

**用户模拟器**是用来与对话系统进行交互用的。在会话的开始，用户模拟器会采样一个user goal(Figure 2)，同时智能体会试图为用户进行诊断。系统会通过最大化长期回报，来挑选每个时间步最好的回复动作。

>At each turn t, the user takes an action $a_{u,t}$ according to the current user state $s_{u,t}$ and the previous agent action $a_{t−1}$, and transits into the next user state $s_{u,t+1}$.

状态用户状态$s_u=(A,G)$，G(goal)保证用户行为的一致性和目标导向性，A(Agenda)则包含了一系列症状和其状态（该症状是否被询问了）

每个对话都是由用户通过用户动作$a_{u,1}$发起的，该动作包含所询问的**疾病槽**和所有的**显性症状**。

###### Dialogue Policy Learning

本文将对话系统设置为了Markov Decision Process (MDP)，并且使用RL训练了**对话策略**。MDP包括states、actions、rewards、policy和transitions。

**State S**包括了当前时间步智能体所询问的和用户所告知的症状。用户和智能体先前的动作，以及轮次信息。

**Actions A**由一个对话动作(e.g., inform, request, deny and confirm)和一个槽(i.e., normalized symptoms or a special slot disease)组成

**Transition T**即st到st+1的update

**Reward R**是做出动作at后时间步t的回报reward rt+1 = R(st, at)

**Policy π**描述智能体的行为，输入为state st输出为所有可能动作的概率分布$π(a_t|s_t)$。

⑦实验

⑤相关工作

⑧评论

### 5.Task-oriented Dialogue System for Automatic Diagnosis via Hierarchical Reinforcement Learning

<a name='md5'>-</a>[原文](papers/Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning.pdf)

①标题+作者

与上篇自动化诊断文章同属一个实验室，是其工作的延续，一作Kangenbei Liao，上篇文章一作Qianlong Liu2为本文二作。

于2020年在arxiv上发表了预印本

https://github.com/nnbay/MeicalChatbot-HRL

本文核心为将层次化的RL引入自动诊断对话系统

②摘要

使用RL方法时，各种症状是作为自动诊断系统的**动作空间**的，该动作空间比传统的RL任务要大。

③结论

④导言

⑥模型

⑦实验

⑤相关工作

⑧评论





### 6.Task-oriented Dialogue System for Automatic Diagnosis via Hierarchical Reinforcement Learning

<a name='md6'>-</a>[原文](papers/HRL.pdf)

①标题+作者

Hierarchical reinforcement learning for automatic disease diagnosis

使用层级化强化学习的自动诊断系统 同文章5，但是作者顺序有区别

联合一作：Cheng Zhong 、Liaokangenbei

②摘要

本文动机为给自动诊断对话系统配置一个分层级的策略policy结构从而解决实际诊断过程中动作空间大的问题。该层级结构中high-level的策略由一个主模块构成，负责触发低层级的模块，低层级模块由一些症状检查器和疾病分类器组成。

③结论

④导言

某些疾病的自动诊断虽然已经达到了很高的准确率，但是每种疾病的诊断都需要该疾病详尽的EMRs作为训练样本，并且训练出的模型很难推及其他类型疾病。

本文基于RL的策略学习方法将任务表示为MDPs马尔可夫决策过程。在每轮交互中，智能体要么选择一个症状去询问，要么从症状和疾病的动作空间中选出一个动作做出诊断。

具体来说使用了HRL方法将自动诊断系统构建为了两级层次结构：1）high-level 2）low-level

>The high-level policy consists of a model named master and the low-level policy consists of several workers and a disease classifier

高等级的master model用来触发低等级的模型。worker负责询问某一大类的疾病症状，疾病分类器根据worker收集的信息，负责做出最后的诊断。该架构模拟了一群不同科室的医生一起诊断病人的过程。其中的两个层级是联合训练的。

contribution：

1）基于RL的自动诊断方法 2）在three public datasets from the real environment and synthetic datasets上对模型进行了系统性评测。3）发布了一个可用作对话诊断系统的benchmark的工具

⑥模型

![1677134307617](论文精读.assets/1677134307617.png)

本文的两级结构分为四个组成部分：1）master 2）worker 3）disease classifier 4）user simulator

在第t轮，state $s_t$会被编码成一个one-hot向量来表示每个症状和master以及worker的轮数。其中的症状信息将被编码用于疾病分类器的训练。

两级模型的交互如下：

![1677134929833](论文精读.assets/1677134929833.png)

⑦实验

实验使用的数据集有：三个对话数据集MZ-4、MZ-10、Dxy，以及一个生成的数据集SymCat-SD-90，数据统计信息如下：

![1677138620475](论文精读.assets/1677138620475.png)

实验中用的评价标准：Acc评价疾病准确率、MR(match rate)用来评价不明确症状的召回率、AVG.T表示诊断所需的会话轮数



⑤相关工作

⑧评论

### 7.DxFormer

<a name='md7'>-</a>[原文](papers/DxFormer.pdf)

①标题+作者

DxFormer: a decoupled automatic diagnostic system based on decoder–encoder transformer with dense symptom representations

基于decoder-encoder结构使用稠密的症状表示的**解耦的**自动诊断系统

②摘要

自动诊断需要与患者持续交互来获取潜在的症状从而支持诊断。现存的方法往往忽略了疾病询问的重要性，即并没有充分地与用户进行询问交互。本文提出的DxFormer则解耦了症状询问与疾病诊断，单独去优化两个模块。症状询问到疾病诊断的过度取决于一个stopping criteria。DxFormer将每个症状作为一个token，将症状问询和疾病诊断形式化为一个NLG模型和一个序列分类模型。本文使用倒置的Transformer结构联合优化强化奖励和交叉熵损失去学习症状的表示。

③结论

本文limitations：

> (i) in this paper, the stopping criterion is simple and crude,and its reliability andscalability shouldbe discussed;
>
>  (ii) in practice, agentsshouldbe allowedto ask multiplesymptomsat one time rather than a single symptom to improve efficiency; and 
>
> (iii) it is not enough to use only the symptoms for diagnosis. In the actual situation, more factors need to be considered, including medical examination, pastmedicalhistory,surroundingenvironment,etc

④导言

疾病诊断的过程就是一个Q&A的过程，医生提问，患者回答。RL方法的症状召回率低于30%，这是由于其在问诊过程中只是询问一到两个症状就急于进行诊断。而实际情况平均一次问诊平均会提到7-8种症状，不充分的症状收集会导致诊断的不准确。DxFormer相较于之前的工作则大大提高了症状的召回率以及诊断的精度。

Transformer-based decoder–encoder structure 中decoder用来进行疾病问询，encoder用来疾病诊断。decoder即以症状为token，以问询为输入进行下句预测conditional text generation task; encoder则将收集到的症状拼接起来作为input来进行a sequence classification task。智能体只会在问询了到达threshold轮次或者最大轮次后才会切换到诊断。

###### main contributions：

>(i) we propose DxFormer, a decoupled system for automatic diagnosis based on inverted Transformer, motivated by approaching the performance upper bound of diagnostic accuracy by improving the symptom recall; 
>
>(ii)we discuss the impact of the maximum number of turns and stopping criterion threshold on the model performance and suggest ways to utilize DxFormer in practice; and
>
> (iii) extensive experiments show that the proposed model achieves the new state-of-the-art (SOTA) results in all the three real-world datasets.

###### Symptom attribute:

症状的属性标签，1）Positive代表患者有该症状 2）Negative代表患者没有该症状

###### Structured MCR：

S为一系列可能的症状，D为一系列可能的疾病，A代表可能的属性。则结构化的MCR可以被定义为$\{ (s_1,a_1), (s_2,a_2) ...(s_n,a_n),d\}$

>ai ∈A is the corresponding attribute of si ，and d ∈ D is the disease label.

###### Explicit and implicit symptoms:

通常MCR中的self_report部分属于明确的症状，而问询得来的为隐藏症状。前k个明确症状定义为$S_{exp}=\{s_1,....,s_k\}$，不明确症状被定义为$S_{imp}=\{s_{k+1},....,s_n\}$

###### Patient simulator:

denote the patient simulator as P, 其input为症状symptom，其output为症状的属性即POS/NEG/UNK，其中UNK为当问询到的symptom不在隐藏症状中时的属性。

###### Agent:

给定病人的明确症状$S_{exp}$与其属性，agent的任务就是从症状$S$中选中一个与Patient simulator进行交互，得到反馈，选择下一个症状继续询问，往复几轮后agent进行了诊断。agent的目标是学习一个可以高效找到隐藏症状的策略。

评价自动诊断系统的评价标准：

1）symptom recall (SX-Rec) 
i.e. the proportion of implicit symptoms that inquired by the agent

2）diagnostic accuracy (DX-Acc)
i.e. the proportion of correct diagnosis

If SX-Rec == 0：
	only explicit symptoms $S_{exp}$ as features
	consequently call accuracy lower bound (Acc-LB)

If SX-Rec == 1:
	both explicit and implicit symptoms as features
	consequently call accuary upper bound（Acc-UB）

  ![1677465347847](论文精读.assets/1677465347847.png)

上图仅有POS属性数据和NEG属性数据的准确率表明了both positive and negative implicit symptoms are useful for disease diagnosis

⑥模型

![1677484233260](论文精读.assets/1677484233260.png)

由于疾病S的动作空间非常大，从而会导致问询的效率低，[HRL](#md6)则解决了该问题。

模型中的decoder可以被看作是一个agent，该agent与patient simulator P进行交互，whose parameters $\theta$ a policy $p_\theta$

##### Reward setting

###### Priori reward:

一个具体的疾病往往与一个症状群相对应，因此agent应更多地去询问一个具体疾病的相关症状。本文通过训练集中的疾病-症状共现频率矩阵来实现。（==数据量足够大时，模型会自己掌握规律，而数据量不够大时，需要引导模型去感知规律==）
对于症状$S_{agt}$如果症状和对应疾病共现的概率超过0，将会给一个+1的positive奖励，否则给一个-1的reward

###### Ground reward:

当$S_{agt}$中的s也在$S_{imp}$中时，将会给予+2.5的reward，否则-0.5的reward

Priori reward是为了防止agent询问无关的症状，ground reward是为了促进隐藏症状的发现。

[supplementary](papers/btac744_supplementary_data.pdf)中对于reward的设置进行了讨论。

##### Training objective

$S_{agt}$的每个动作的reward = Priori reward + Ground reward. decoder的训练目标为最小化负奖励
$$
L(\theta)= -E_{\tau～p_{\theta}}[R(\tau)]
\tag{1}
$$
训练时对于给定的患者明确症状，将会由decoder通过采样编码和贪婪编码分别获得$S_{sdec}、S_{gdec}$，前者用来计算强化学习reward，后者用来计算交叉熵损失。最终的损失函数等价于negative REINFORCE reward and the cross-entropy loss

##### Stopping criterion

在训练过程中，作者定义了最大轮数$T_{max}$，agent的目的就是在最大轮次内尽可能询问到多的隐藏症状implicit，并作出正确的诊断. 
由于大多数诊断不需要达到最大轮次即可获取到关键症状.因此本文又在每次问询后,将已知的症状拼接起来放入encoder中计算可能的疾病概率分布. 本文定义了一个阈值,当多个症状放入encoder中计算出的疾病概率高于该阈值时将进行诊断.

⑦实验

评估使用了三个真实场景中收集的医疗数据集: Dxy、MZ-4、MZ-10

使用的baselines: DQN、REFUEL、KR-DQN、GAMP、BSODA

实验结果如下：

![1677760429814](论文精读.assets/1677760429814.png)



⑤相关工作



⑧评论

### 8.Diaformer

<a name='md8'>-</a>[原文](papers/Diaformer.pdf)

①标题+作者

Diaformer: Automatic Diagnosis via Symptoms Sequence Generation

一作Junying Chen 哈尔滨工业大学

二作李东方 https://crazyofapple.github.io/

导师陈清财 http://faculty.hitsz.edu.cn/chenqingcai1

使用症状序列生成的自动诊断

[视频讲解](https://www.bilibili.com/video/av593290326/?vd_source=c98fad59c69f91a794e1744235745aa0)

②摘要

近期工作通常使用RL来解决多步推理的自动诊断问题。但由于其低效以及需要任务相关的reward函数。本文提出将诊断过程看作一个序列生成的过程，生成内容包括诊断和症状。据此提出了基于Transformer的自动Diagnosis模型Diaformer。

本文首先设计了症状注意力架构，进行症状询问和诊断。之后为消除生成的序列与无序的golden隐藏症状之间的差异，本文又设计了三个无序的训练机制。

③结论

​	

④导言

![1677636309144](论文精读.assets/1677636309144.png)

上图例子对于RL方法来说将会从大量的动作/状态空间使用策略学习潜在地学习到询问哪个症状可以帮助诊断children’s bronchitis。而Sequence Generation (SG) 方法则基于明确症状学着去依次询问sore_throat、fever和brash breath

contributions：
1）第一个将症状序列生成应用到自动化诊断中。
2）提出了三个无序的训练机制去缓解所生成的症状序列与Golden症状集合之间顺序的不一致

⑥模型

![1677637568144](论文精读.assets/1677637568144.png)

Diaformer由symptom attention framework和orderless training mechanisms构成，上图为前者。其中每个block都含有一个前馈神经网络和一个多头attention。

###### Input Representation

如图(a)，$S_{exp}$、$S_{imp}$中所有症状都将转换为特殊token embedding。并且该输入表示为对应状态、疾病名称的累加和，但没有position embedding。

###### Attention Masks

图(b)中的掩码矩阵是为了防止症状预测在自注意层看到泄露信息，实现隐式症状的自回归生成训练

###### Symptom Token Attention

图(c)为初始化隐藏症状的token embedding

######  Decoder

如图(a)本文引入了一个长度(n+1)的序列去训练生成模型，其中n是隐藏症状的长度。图(d)中展示的是序列的注意力流。[D]在输入序列中可以注意到所有的症状，将用其来进行疾病分类。

###### Orderless Training Mechanisms

三个无序训练机制：

###### Sequence Shuffle

随机打乱了隐藏症状序列$T_{imp}$的顺序，因此多轮训练后模型可以学到不同顺序的疾病问询，该方法可以提高模型的鲁棒性，即避免了使用特定的序列去问询的数据去训练出的模型，在问询序列仅仅在顺序上稍有改变就无法继续进行。

###### Synchronous Learning

在模型预测下一个症状来进行问询时，未被询问到的症状应该有相同的概率被问询到。

图[a]中$[S]_1$被训练来预测Sym3，而Sym3、4、5应有相同的优先度被问询到。因此本文设计了同步学习目标，来使其同时预测那些自己看不到的隐藏症状。

![1677740664410](论文精读.assets/1677740664410.png)

如上图，每个症状预测token[S]同时被训练去预测所有的隐藏症状。因此本文使用了并发的softmax

###### Repeated Sequence

由于自回归生成，模型每个时间步可能会学到一个具体不变的症状生成顺序。比如图[a]中模型可以学到Sym3 → Sym4 → Sym5的顺序去问询，但是不能以Sym5 → Sym4 → Sym3这种顺序。
本文解决这一问题采用了将重复序列与input序列进行拼接的方法，来使模型学习到不同的生成序列。
如图[2] $[Sym^{`}_{5}，[S]^{`}_{2}，Sym^{`}_{4},[S]^{`}_{3}]$该序列的添加即为能使模型生成Sym5 → Sym4 → Sym3的顺序。

###### Generative Inference

推理阶段首先会在症状序列后面插入一个预测token[S],来计算接下来症状的概率分布。对于已经咨询的症状会用加MASK。

![1677742907683](论文精读.assets/1677742907683.png)

用户模拟器将会决定问询的症状是不是在golden implicit symptoms中。如果症状不在其中，则模型会问询下一个概率最大的(==此处与DxFormer处理不同，后者将不包含的症状也会收集并打上Unknown（UKN）==)

<u>有限轮数内无效的问询是否被减少？</u>

当模型预测到END符号的概率比$p_e$要大或者推断到的症状比$p_p$概率要小时模型会停止症状的问询转去进行疾病诊断。

疾病诊断时，本文将token[D]插入到症状序列中去预测疾病。(==此处与DxFormer使用单独的encoder不同==)

⑦实验

本文评测使用的数据集有：MuZhi、Dxy、Synthetic

![1677747171314](论文精读.assets/1677747171314.png)

~~其中Dxy使用的与DxFormer不同版，本文为18年，Dx为19年~~

实验结果如下

![1677759708673](论文精读.assets/1677759708673.png)

对比上下两图，Flat-DQN在两个版本的Dxy中召回率相差过大，并且本文实验结果中其精确度和召回率反而高于了HRL，因此数据不同可能导致了Diaformer在召回率上虚高于DxFormer，同时需要注意，Diaformer的平均问询轮次比DxFormer高了6~7轮

![1677762833243](论文精读.assets/1677762833243.png)

![1677763341593](论文精读.assets/1677763341593.png)

###### Ablation Study

![1677822714870](论文精读.assets/1677822714870.png)

消融实验主要对三个训练机制进行了w/o分析，可以看出Sequence Shuffle效果最为明显。==由于DxFormer使用encoder进行诊断，而本文使用decoder，因此省去了orderless训练机制的选择；应比较两种方案的优劣==

⑤相关工作

⑧评论



## Corpus

### 1.ReMeDi

<a name='c1'>-</a>[原文](papers/(ReMeDi)Resources for Multi-domain, Multi-service, Medical Dialogues.pdf)

①标题+作者

ReMeDi: Resources for
Multi-domain, Multi-service, Medical Dialogues

多领域多服务的医疗对话数据集

作者团队 山东大学信息检索实验室

https://ir.sdu.edu.cn/

②摘要

医疗对话系统(Medical dialogue systems, MDSs)旨在为医生和病人提供一系列专业的医疗服务(i.e., diagnosis, treatment and consultation.)

但由于资源的缺失MDSs的发展受阻，具体来说：

1）没有一个涵盖多种医疗服务的且有精细化标签(i.e., intents, actions, slots, values)的数据集

2）没有已经建立好的MDSs面向多领域、多服务的医疗对话

ReMeDi中文医学对话数据集包含两部分：1）ReMeDi dataset 2）ReMeDi benchmarks

1）中具体数据量：

>The ReMeDi dataset contains 96,965 conversations between doctors and patients, including 1,557 conversations with fine-gained labels. It covers 843 types ofdiseases, 5,228 medical entities, and 3 specialties of medical services across 40 domains. 

该数据集为目前唯一一个涵盖多领域多服务的并且有细粒度医学标签的数据集。

2）中提供了一系列医疗对话生成的SOTA模型，具体方法有

i.使用预训练模型(i.e., BERT-WWM, BERT-MED, GPT2, and MT5)在本数据集上进行了训练、验证和测试。

ii.使用自监督的对比学习方法(self-supervised contrastive learning, SCL)去扩充ReMeDi数据集，从而增强在SOTA预训练模型上训练的效果。

③结论

④导言

MDSs由于需要大量的专业知识因此比一般的TODSs更为难一点。具体来说有很多专业术语使用了口语化的表达[AAAI-2020](papers/Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses.pdf)

现有的数据集仍具有的缺陷：1）数据集中没有一个完整的诊断和治疗的流程。实际中的医疗对话通常包含有询问、诊断和治疗，如下图：

![1669885265014](论文精读.assets/1669885265014.png)

2）当前可获取的数据集中标签并不够全面，大多数数据集仅仅提供了每一句话的slot-value对，且每句话中相关的intent标签和医疗知识三元组很少有提供。

例如[A Medical Information Extractor towards Medical Dialogues](papers/(MIE)A Medical Information Extractor towards Medical Dialogues.pdf) 中的：“Patient: Doctor, could you please tell me is it premature beat?”该句话对应的数据只有slot-value对“Symptom: Cardiopalmus”，而没有intent标签“Inquire”，也没有所需的知识三元组“<premature beat, symptom, cardiopalmus>”

3）当前的数据集中标签不够细粒度化。比如上图中病人说的"I have been this ten days and have a sore throat. What is the disease?"其中包含了三种intents: informing time、informing symptom status 以及 inquiring diseases。而先前的工作仅仅为整个复合句提供了单独一个粗粒度的标签，这可能误导模型的训练导致不精准的评估。另外，先前的工作定义的values值不能精确地传达复杂信息。本文提供的数据则使用了主从结构的values，即每个value都包含一个main value和一个 subordinate value。比如“Value=duration, ten days”中主标签为“duration”，子标签为“ten days”。该主-从value结构有着更强的传递复杂信息的能力。比如可以表达：
a）一个实体的否定状态，e.g., without experiencing symptom sore throat 
b）实体具体的value，e.g., the specific number of blood pressure
c）实体间的关系，e.g., the side effect of a medicine

4）一些数据集仅仅包括有限的医学实体，比如近期发布的数据集[MedDG](papers/(MedDG)An Entity-Centric Medical Consultation Dataset for Entity-Aware Medical Dialogue Generation.pdf)中仅包含了12中疾病

**ReMeDi的特点：**
1）咨询、诊断和治疗相关的医疗对话，包括三者的混合。
2）全面且细粒度的标签 e.g., intent-slot-value triples for sub-utterances
3）超过843种疾病，20个槽位和5228个医学实体被覆盖。

Moreover, we ground the dialogues with medical knowledge triples by mapping utterances to medical entities.

近期的MDSs都采用模块化(NLU、DPL、NLG)，但模块化的设计方案使得同时完成或评估所有模块时无法及进行全面的性能分析。
 为了建立一个共享的基准测试，在MDS设置中处理NLU、DPL和NLG任务，我们采用了因果语言建模，使用几个PLM(i.e., BER-WWM, BERT-MED, MT5 and GPT2)，并使用本数据集对其进行了微调。

⑤相关工作

###### Medical dialogue systems

MDSs现有工作一般都是模块化的即分为NLU、DPL和NLG
NLU模块通过进行意图识别和槽填充来理解用户的输入语句。

DST模块追踪用户意图的变化。

DPL模块通过给定的一系列槽-值对对话状态以及对话上下文信息来决定系统动作。该模块大多数都是使用RL的方法进行。为了避免在这些RL模型中进行动作空间的探索，本文将系统动作生成为了通用token。

NLG模块根据NLU和DPL模块给定的输出去生成系统回复。

⑥模型

⑦实验

⑧评论

### 2.A benchmark for automatic medical consultation system: frameworks, tasks and datasets

<a name='c2'>-</a>[原文](papers/.pdf)

①标题+作者

一作：陈伟 http://www.fudan-disc.com/people/wchen 

魏忠钰组博士

实验室 复旦大学数据智能与社会计算实验室 http://fudan-disc.com/

②摘要

本文提出了两个框架去支持自动化医疗咨询，**医生-患者对话理解框架**、**任务导向交互框架**。并且创建了一个新的大型医疗对话数据集，该数据集有多级别细粒度的注释，并且创建了五个独立的任务。五个任务：**命名实体识别**、**对话动作分类**、**症状标签推理**、**疾病报告生成**、**诊断导向的对话策略**。

③结论

④导言

远程医疗时，患者通常要先提供一个self-report，之后进一步沟通，最后做出诊断并给出医疗建议。记录该过程的电子记录为MCR。

目前自动化医疗领域的工作与现实应用之间的gap为：1）缺少框架和任务设计 2）缺少benchmark数据集

本文即构建了第一个自动医疗咨询的框架，并且提出了涵盖整个流程的几个任务。提出了两个模型架构分别去支持对话理解、任务导向交互，分别是**dialogue understanding**和**task-oriented interaction**。前者用来抽取对话上下文中抽取结构化信息，并且生成有用的标签去描述对话状态，比如病人健康状态、病人意图。后者则是学习对话策略。

main contributions：

(i) we propose a design of frameworks and tasks for automatic medical consultation and introduce **IMCS-21**, a large-scale annotated medical dialogue corpus, whose superiority makes it potentially a great benchmark for medical dialogue modeling; and

(ii) we created neural-based models for each task and report a set of benchmark results.

⑥模型

⑦实验

IMCS-21在Diagnosis-oriented dialogue policy任务上的实验结果

<img src="论文精读.assets/1677899433196.png" alt="1677899433196" style="zoom:67%;" />

⑤相关工作

⑧评论

---

### Task-oriented Dialogue System for Automatic Diagnosis

https://blog.csdn.net/Getugly/article/details/125421053

---



### Task-oriented Dialogue System for Automatic Disease Diagnosis via HRL

https://blog.csdn.net/Getugly/article/details/125420501

---

###  Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical Analysis of System-wise Evaluation 

 SIGDIAL 2020最佳论文研究贡献 

一作清华大学CoAI团队[高信龙一](https://truthless11.github.io/)



https://new.qq.com/rain/a/20200714A07K4H00